{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2BcHNg450s9C",
    "outputId": "7008fde0-7ea8-4d3b-e60c-f85f6a828b46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.55.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.34.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.8.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z0YPSvnI2K0P"
   },
   "source": [
    "Hugging_face_Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "b7472cb96a6b41f6a19597a3a0a28bae",
      "99c84101b3e64e788c32e73ce4286e99",
      "0bd33e6dbf254920b0468e7fc1215a26",
      "860858658deb4571853df9187e83b15e",
      "ecb8c54fe6c244229d416d2e57cf0add",
      "4162a53fbf924160a1c703d657d08b74",
      "316b48889f674b7c8300593a0760f631",
      "d43181aa92e943bc84c72a53ab8ecd7f",
      "46d0b8e7dc6442ae87bd5586343f5aea",
      "40595af95c6a4943ba4e27d05e502cc6",
      "22cef304094747f6a1dcf866952f71c6",
      "b79ec80393f44f7fb04e04ecb9486f27",
      "491d0c9d564942dd846442d448e75fd8",
      "c674ec48115e4907a7a9ffb93c919dce",
      "ba15e2f403cd4eac8bf20c935950e4ad",
      "317a392e9cbc4964ada8ca06079e791f",
      "22545cc16e0f4dc59eaaf08fea89cefe",
      "c2149e44a1334bf8a64007a19e44d104",
      "6bc7f43829b34371a37d593264b5e660",
      "8c0442b29c92463da464d4846d55ee92",
      "ac0c921fb3e34df79ce66a67892e9584",
      "cc0123b820e745498ee4898ff06ec1db",
      "7cbd1bb81bb446b8938c95e96f5770df",
      "5e55ee4b7d6d48fd96e55e5f1b59b625",
      "cdb524adfe5040efa3afa97635211f1c",
      "53e8346885df4b308686c0eaeb8473f8",
      "0c28f2ee156f4ac380726bcf2ca66e84",
      "5e42e6ef675a45de8a95e4103cb2cbdf",
      "f985c261abd249398a24fc9af49f6d68",
      "811a9ef6bd4d4d9ca0fe7d8e880613e1",
      "e35fa52c44a744ac8626f0e7d77e9c49",
      "a47e693fa0e54fb0893b755f44890cec",
      "24c892b6c88548eeb5d3ea04258b5313",
      "23d50f151279477fa182dfa6c05924d4",
      "a4423ef33586459da3a1322dda6b92ee",
      "7cb639ecad6142f69b49fb1dc2b62dd4",
      "b0b71bc959e548a7815e4b7655765dd0",
      "c23ea5df699e43719685f3010f9896d1",
      "b5fd4099ae7b4c1ea720fdea70ff18fc",
      "fe0d3e2d6e904fd6bc021fc4d82068e3",
      "cb849549da0d4a8aa2f94cde2f31ef1a",
      "62cf0dbeec5b410d9b29ebd591ef9d0b",
      "e86b4e6ab7c94750b32a60b590606b43",
      "d0c035d05bc04a08b62e8a54a4afda15",
      "cd6777287abf4470a03a1c327546a800",
      "d1070ed7ee674bc9b2d631a587f507a0",
      "5712ddbfb1824bc883c92bc7994f11f5",
      "4daa7c423a4d4f1098197796346ae9ef",
      "47f752cdab5a48e697b90b34576c38b2",
      "1edcbbdf4559435cb74f846b9a64dced",
      "9cbc333c049646a68412bf37fe098932",
      "c0e28db22d734e36ad595b9da37825ba",
      "d4ed67cdf52b44f89b8840e44a98b63a",
      "cea8c2bd97a74587aa8066261a4213e0",
      "8146518cb0b243f1b029167b17abcff9",
      "f53ef7e4c8bc4affbc1e26dd13bf21fb",
      "96eca669188a467c8c0b37001eced339",
      "95d215b952a84e6589993dbf802bc06a",
      "200e736b5c854f99916fc16fcfe336ec",
      "8e64e5ddaa8440dc87ee257223668a13",
      "8a94f131606f4da58f7d0582e2aa67ec",
      "38a78df3b7ef4d91a82c6f16753164f0",
      "6039dbd359914a98aaefec6e81278785",
      "35c91672ceb94932aad7ab0aff6adc4b",
      "b9a7febaa4e845c48f27d84f6e3253ec",
      "4e08d280146e42d5843016828be3af47",
      "f469e5720ef94c01aa7e0147e3903694",
      "35e8e2c2ea964711a2b6348edb09b3d3",
      "ecbb3c36d659429ea1535855224b311c",
      "99f09ec06c774139bd216ea7b5b6fd14",
      "2981e5011c644411beeb3a94040ad4bb",
      "a1585e1014754a3fbee0b015bbc8b7e4",
      "6e10ed8e00954e5bb0bcdcc4cc8a6421",
      "5f987e6e7e7346d9b53f8077f7ade9d9",
      "e478650824ab40b8a02a3b8b660ffd4b",
      "295fcff2086149b4b7592f0fb5aa882e",
      "7b2bdcbc387743c58a0a10159c8c6a68",
      "3327841f45a34bf4854aa6cd556d14b1",
      "3f269d0f6d094b09bb1bad41eb9b935a",
      "3b696f72c5d3440296e654a36955c672",
      "0cc4b6abfd2c4351ac2fffca5983144d",
      "e877bd08d36545dfb2a7a22a8531724c",
      "6d6a87d1fa2b4b9483ea40d8a62321b5",
      "37a0358e400b4ca6b1f13dfaac6838c1",
      "b7209756dcce4a578d764b6ca73a4c13",
      "94dc7c0427b14ed5857bb7c71930fde3",
      "efffceb655bb41f8b699df350f1285cb",
      "e288662303914d86b82c1a8dee50d598",
      "9000deb57f0f4f65a9793fc3eb1e70ff",
      "383c5c7ed3c44a788b72b271cc9bfdb7",
      "cd547409d1794705bde8011439841e9c",
      "24f1524fd1ed4f82982713daf573bf3c",
      "b4de571aa18d4da88b462714570e9aad",
      "7dabd33b9a9d4d1794e7b5ef6784adb0",
      "0743c069b81b4b5ab47591c347b21c66",
      "ed625db182304a538df2a75923227aaa",
      "a93d4e70cf9c41ccbedf709aba9f9c1c",
      "9987a0522cd04ff8b7b04697bc745783",
      "cd4a59218d3a4f039bfde7fae40bca93",
      "9a81273afc74402fbb1eac71c7d2f941",
      "38fb6d9e86414bc881bf58c6de7a3abb",
      "4d06a605afa442b6b1c61487603041f9",
      "2ed70e496b6440bfb28929b99bce74b2",
      "0bf6401971e34e64824f22d1910b09b8",
      "b26dd0079db04b57aa71ed3f45d0dc33",
      "cbee1253648c40f1aa7c31d87d2ddceb",
      "cd5d796c1e8a40a0b1e41b183a0546d9",
      "c64a4a501fab44da941db7f0f7a32a15",
      "ee7e91dec68f462096e8c5405baa17c2",
      "9c29642c02874b658f0af256804b1b92",
      "349db094cc7a466b99419d823d07b944",
      "c08359dc742e4358b63826c7a14cc8ab",
      "527e4f3e3d4c4b5ebda5ebb7103bfb77",
      "a850188d41a14dacad8ade2de2cf040e",
      "136a024f41ec403dab605237cbb24b46",
      "5ac97747f08243f1bdbcd52c260fb595",
      "8f98e4f9351b4693b9baee88af088257",
      "3ba3d037cf0d484fb2582a50b48e3d2d",
      "db0bd2ec18804b0582aff55a679db125",
      "360b52efe7854205a2a54041c128fae4",
      "258ac582a180491699e3691a21f032b2",
      "20377189c29746628850c3dcf4f962f1",
      "7a6aa0e6d7fd441db062e8b584eb421f",
      "8c1bcd373c95453883c946cb9d254bc7",
      "16e58d41dafd4b27b61a82a4900502a7",
      "3ad6805a3c634f3e97bfba8ff0072840",
      "3d6c77be6ff14cb283739056e5ca6f4e",
      "7e2a7b20de1743b39b9949b5199e19dc",
      "a59f33f61718436ca49fa6fa4b3e7c87",
      "d7af2f250215448c9b50c642084bf2ea",
      "9b4bdf026d0a49a9beec949bd95f9343",
      "887b0dc07300410fbc7beca24458c353",
      "c55fcedf481244069685d041f4c369d1",
      "c4404f7460ee4490aee43a4fe815cd25",
      "6783c12c1bcd4784b8983b3a34298ce0",
      "13174061be5745db9a3faf48420361d7",
      "1b71ea2416dc44c2a2b36e243326d5cf",
      "af285741323e49f0b56e98492b789d78",
      "3faaa1ca9576484587ce8419ad4e103e",
      "23542eb72e264d67a183befd9ac7351e",
      "c3813aa60ad943dab3563170fa392b22",
      "43bcf02d798143ada7135f9f86b3c2a9",
      "f2cfe22a1f284e1b9d3f02da5ea58a77",
      "f3d8ece3cfa542ac8c13b0dd62f79c28",
      "e8b9a6fde77a479790e438a81ed75133",
      "8ac9429d8b6d489786df65fe25c57b5a",
      "13222af9036c4b4f8c9dc47ec63832c2",
      "57096b647b6049d58e8abf25993927dc",
      "c7586bcbff454d6eabc3b61d0375b1d8",
      "245a04192fca4a0bad7b13b25df24ab5",
      "d7a5f806ad4244779ce271047f195a5f",
      "6904518f199e4f3c877bbbd982e76dc4",
      "09216dd3d790421f851985c02bb60b84",
      "77ff5daaf4b349538385e763468efe1f",
      "5865db0a6aaa43b8bcd452e0fd0f89fb",
      "a2bd9bfba1c848ffa7d7dd0539180de4",
      "6dc6f026319b46c6b8bd6334404f30c5",
      "73e0cbfed2fd46588b16d7b7ba1ffd5c",
      "72b82e9e38c94a068a5a21b5a8454ab4",
      "b4fca783e2bb42be817ba008a09b6908",
      "8b6c5b3f3a9648d9b6b5337fe7a6e3fc",
      "a5dbe0ed2ade4dc88cc3ee9fc4ee29ea",
      "00dd67adf79d414db97a467db5d80d88",
      "ef15e8f3ab9f4a8eb15f8b4fe7ae5164",
      "e37f0722ff2c458999eb348afe7b0ebc",
      "7b50cb258f2a4326a05c7c31450b82b3",
      "edeb70d2238c48028dcc95dd6ab992d9",
      "10cf6f8425194dd4a8e60b0cb502a52c",
      "51c05d71af554a2e8017b9b752340d6e",
      "f3d009a5509a4061976dbaf8208d7df3",
      "20dbf049416c45f2a8fe9cd1af69a2c8",
      "99ea87b0203c45ac8afb1669df5b8ca3",
      "0aa4776e509e4e30891edb22fe7f0b03",
      "fdfed55ee56c48da9330a13214097a9b",
      "f15cbfd7ef774943bbf809f8bb1aa66b",
      "a92345162cfe466dbdad47f632d3e169",
      "8a90fa479f5d453f8829bfb328006506",
      "736f0f3c00a94214bfe7cf410485423d",
      "12891f08e7684454b8737ca6c8333376",
      "2716fc5f582d47dbbfb2b32d022c5d30",
      "4a4ffa85301a4afb8f1eaa9857309666",
      "8028071f8295416997e41c2ebdb061ef",
      "629b790726a9488c938cd8d424a18231",
      "ec80a31072d6498e91b62c32a5a9cc35",
      "ac3f7685f2da46b7bb89be9e7bbaa91e",
      "19d26cb0084b4ded824a30e664144f3e",
      "987ae183b8314ba08a423977632fbc18",
      "ecc8a35a872b45a8b528dbccdab23271",
      "50dbf55c8dd84e0d827da42bd668a210",
      "1310f7095c6840f68c78be23b9b12411",
      "6d0b34b01f584b2e9add2dcd26f73c9c",
      "2969171f98794b3dac19214f42e49678",
      "396df28c6c3c472e87e46d7c11f54999",
      "53581f4186924633a3ca8c5720d39460",
      "f2a8323675f340439abc76ba7dd74c1a",
      "d62ebd3b6fed4f0aa5be32fbd21edc89",
      "dec32e1762054e2bb54801a787750755",
      "3ea44fa9dd0a4c76b7d0b01cb99f4416",
      "2def23cb89bd4a00a19a92cac6e9afc2",
      "7a673d51677247b9a593fb235363cc0d",
      "0d8b1bd223fc465ca2264a6fdc3a1c2a",
      "2a62ebe0c2e144d4ac21f1327eabd431",
      "e08d0af24c494c7c93760f3ca5662651",
      "f54ebbda0275493f911430050c826e39",
      "f8cdd431c49b4bc0b566e850f08ca6e0",
      "efae18932e354ffd85008ff792b0a012",
      "60f678570361405ca1e7070bf737d640",
      "bdf92f58892442f68c6bf1548eb4e9e1",
      "9284796b884a4b2f9a20deb85bbc4270",
      "7bf997689d024d6a81b0a771711fd67f",
      "7b35a1b03f4643cabb3998d1f62d9ce9",
      "b549a161bf024d4991a98f964db54164",
      "3a21eee0475546438cf36ab907bbe778",
      "49a2bd8cadfc47aeb678f46fc6c2d14a",
      "c1adcd4a25dd45bcba73b523bbf671e4",
      "5a9aac9f69304a71bfebcfda39920f13",
      "7264c26f5c33415dbd66c6281a261fdd",
      "2c9908b21e4c43679fde1aebdb22520d",
      "db0296fecae344a59fb23ee740dd29f4",
      "0c5ead2a0a2c4112a73e7b36773d4632",
      "8577660079184297bcfa149efce52920",
      "77f88ae6391945f0bec5a5354bc0f733",
      "881a6ac2d25e4db5b5419219853980a5",
      "069236549552444abea8b8dc79f12b71",
      "56c7e980373a41ea9166bb6a1c4f1e3a",
      "2f4b74a6ffbe44178b8c24c4142bccc5",
      "9c298b6323af4577b0db235568ce53ff",
      "8f0503524d654b76ba90fe88685b40ac",
      "a361394526914cf39b588709c7a683a9",
      "28bd7327c25b4d8ebdd6e3a59ab37272",
      "8ec34aa0d47c4a27984d848fde106dab",
      "6b5777f60b7548a1ad5278596f4308a7",
      "46cc54429c0349a7899cc90e081cbeb9",
      "17805ff1655d49e29c88ea6c047b8a7f",
      "a967b9b4c9ab428a9c860342c71420d9",
      "951ab588fd6649d99273c7cfbd520475",
      "0b38e1c24fa04c52bc8eea679e229924",
      "83322176b60e4995948f6e660597980d",
      "2de99e4716be46ec8ba13d9748112dda",
      "441aa2a6ec76401abf04edccea3f67ef",
      "fe67267d0a434c65a64a9a4412f19ec4",
      "0d86109de64e4b43960a36168f99d33a",
      "a1fe122408c542b8a28c2e967d421562",
      "6a5afe6b56c149f9891f0a54d60dfa3a",
      "1e102f19927249178e9eacba32427699",
      "f2a54f9aba8a4bc0bf5c190ae9a7b092",
      "97d2ab7e9c10425b9a0471d826e068f8",
      "89fe2c119d88483082f241146d8f9ba0",
      "f6be33a0ad584bb0afe64436a99f9d1f",
      "11ead62dca7d4d41beae034634c8ca26",
      "334a14f71c5c411d884f07971072078b",
      "441d1a3a25eb465c9b464739faee9bcb",
      "3a46d564ac024580a89c34f76447160e",
      "658d91be94064382bf36fc8be0df0641",
      "1e714f5646a940ec96fea813640c97a1",
      "b0c7d7523d7d40738322a9a341fccb6e",
      "eebe5053ac3845fcb2f9090324710941",
      "ccd8bb0640f54aaca0e06494367fcf61",
      "1788bc1e26114986a17d16b48fbae596",
      "d135dc17a94f4a43a651b88e5b8b314f",
      "0fbdd18da476400bad6249d89e86bd77",
      "f00bac6cae6b4035b21a6555809e1161",
      "a58ce2417cb34976b6ddcedb45a83d32",
      "fbf4529cd2f2427eaa967d25cdd13f3c",
      "627b3bc7049845beb759dc578bf43bc2",
      "49ae75d7c2c94bc68dfbb2e0b249882c",
      "6b31ff3d85534a68b01c183d45249e13",
      "9c4f88d1fec94eeabfaa8d0171359d26",
      "772da52b1d514ab983fcfb992960466a",
      "d8cc18ee687142d888dbd57ca2e5f6dc",
      "b0d0103f15cd4c168fc0b18220c8d48f",
      "cb23dc58634247bebc1ce6d26685e546",
      "b9455d28d6fe4b2cb193a96678c829b1",
      "7c5861242ef34d43bf2bb4513abdc22d",
      "09cc19e0d9004b4f8239431f6d388ec6",
      "53b28a36dc9b4374b7e46166821186c8",
      "90cd7565c9a54eaaac87667ea0d5c69b",
      "575e88cca4de4de5a8d45583378888e3",
      "845cc581d26042658d9c72007337e7f5",
      "a3de1f4e3bf94280bcfbcf30c97afc46",
      "ef606485e3594e70a90835f694d0ecb9",
      "d66d2ae393434a87a9394a6e7ce32391",
      "479c0ca0b1a2464891a0e046f512594e",
      "40334a420a76490e9892c3b2312077ff",
      "0ace9c1329f14f26a04e2b1b254faa23",
      "747ab5ee647747b1b49bce41ece1d55a",
      "9a37b7c370f342bd97b706fc9997f845",
      "0853144534e54dd5923a6559a983e434",
      "f999436127d84cfcadcbf7002e8ac87a",
      "35a1d44887c24cf9ada2d0d5ca919791",
      "672b1bb29d3746a688328a83b2755d4e",
      "879ff4e9547e4221a71344dc8dc51a4a",
      "01243efa881c45229ed98e1ecf7b3302",
      "6ca9f33330524bc98b6bf59bbd2c02d2",
      "dd66ee00f5f249e185050d3d146e26e7",
      "a697c24a608149d997ee82411d4616f3",
      "786f84f4dd1242f0801100f7c28432ed",
      "5f394f808c084b7eb8e8a20fabf44c00",
      "314191d2c5bf4021b66f265bbc2c2f7a",
      "3ca5c2d685d645cea0530adee9c335ec",
      "5082176633a64ada89aee8f0fff5912b",
      "4ef5953351a64a1485c968c70022ef12",
      "cdd6bcf4749f402e98bcb78477d1a6bf",
      "8711f908f8bb4a8580021c1f4ed5ba07",
      "01edf21f1b16411aa59c06d4f791078c",
      "63b0910b57f645a89734abc37f715d2e",
      "4e50107789df446fafad9e8a747d2745",
      "f1e3d62b6ed54095851a53a978562862",
      "7af971e2ae5e4e08ae9baffcaf402c41",
      "0e112a38b0014e258499194a705abcef",
      "611e16d4a14b45febd11e5f042b2c0d0",
      "0d48c35a08234629be3d0b687d4c5bcd",
      "79831018f36f4392a50c38932c8dc0cd",
      "bfe8ab9f519e401da2ba419427ce3854",
      "178a90073a1c4958878dcb3aa7523196",
      "a3ec5c1858ce4304888ff059d1acf22f",
      "ae3bde94b17a48cab3ea6ff09873c5f4",
      "aa87bfe2854248c5b38b284e59a3f332",
      "e75e0c9948a1488284b08e0d2c0845c3",
      "6f46dfdb8575439c8cd563df3cd5d1a4",
      "9cf9d7999946489c8c612c8f6feffd6b",
      "32aa52319354493e855f5ffbe3463dfd",
      "9b0eda448c9a438e8e6266292e4a6b35",
      "84e43d2bbf9a441e89936a50edd00b16",
      "9b616fb9881a4d5fbb760afdaea3b682",
      "89d7e1d3db814b72b40623dd0909f0eb",
      "f8a1a19ab812475bb635931c1f85b031",
      "74b6fc146e88410fad640e366ac232f1",
      "b11f2dd2a37443bf9a081f3f0f68f361",
      "0581f7a6bc6c4abc828fa2f341992373",
      "d0c693df1c22449f833f66208a4d5feb",
      "fa05a4e02af642b0a61c7a9bf64ad473",
      "b149a3fef7754d1f9bfc213fd612df22",
      "ce04e764b74a4503a6953b821e693027",
      "b4191acc40b34aa7829ff6246d1edbdd",
      "88a6f9e0eb8b4425bdbb976c5583d4a5",
      "d19a9bef86e646ea8d1436719e97f7f1",
      "7ba59d3ed4264cdebf98d511b89cb9a8",
      "fac0aad23743495eab0aa5cfc3897746",
      "4f05950c8af34172993b0fcddf4eed8c",
      "a6beeb6ed0b94eea8f8949abee19343b",
      "5e074f4705a64a4db48230d03290f995",
      "8f84c9ab0af24ff3a879317aec7e9a3f",
      "9fc747e7930947e6a11be14e108bb189",
      "d3185b2e7fbd4cd3a8bd5a75b36761c6",
      "f0512a485e8d4f1d8421080e3642c251",
      "ccdf513350a247e1b4129f796782a5f0",
      "54bb89b3f4174a598b9330d53676faa6",
      "34715c5c39b0404f884fa77dcf6f3e3d",
      "a1ac28c1658a4a38a821c691561b8c59",
      "f76034034e834ab4a442ae16c5c68aea",
      "6f2d1d5057eb42cba8c55a16fdda47c3",
      "4b5f69d4366b4e71b5fe1211788c580f",
      "18426df081084874aa27590d3c687d29",
      "6183a1e067c74072ac85c81e47e8aa8a",
      "cba35318520140389cd6c2373723bde3",
      "ade4f3993b7b4806bb00138e13bf3bdc",
      "ffd78398f2ae451c94cb4e9897e25aac",
      "ac28d0ce74bb427ca4a3daa1afc28526",
      "c213986574ee42dea8805eadc7047868",
      "526f5c98580b4731943d74647be57f62",
      "ac1b335c8cee4782994d045f175705bb",
      "9cac48bb5ee34001b1fc9a7070ce1f53",
      "72b9fc0c67bb41b9ad731c43139f2edd",
      "9e2d0835b2c3489fade8259ad7e6b597",
      "446ad7ba24d0428680abb42e0a5a220c",
      "58c56a60ff134e159fa35f2d7ecf43fd",
      "c352c96fc1cb4a158f70b49880c8e7fe",
      "7a4f79a9d577446c9840c737b71caea6",
      "149edc46f8014e1b80b729846ef033f3",
      "ca0a6a1b3baf4e1185f8eb9a8a27be9f",
      "78df3301f9cd4549bfbd265c98b90689",
      "a8d03bc650834be595768ee926ec9de8",
      "ffe3ea4ac97e4f4ca89fd06652e481d9",
      "382d2cba007f415ea957b526a2c56c4d",
      "6bc8345670d4454c982e1b37aa26028f",
      "e23e08847541402fbaf47e67b86e28c2",
      "cd12f343f5aa4094b0036ad6628a9282",
      "6f048b3d606f4c5992ac54737e266841",
      "e90650f5aa7f4837844aed1beccb0068",
      "bb17a4824b594cd98c65b8fc493d1dcd",
      "bb02ac23447a4731a5846bcec00658c0",
      "440cb38acf954911950ce500ca7ef2df",
      "2cca6544eb8f44daa38acf71003f69d0",
      "5c4038ac3aeb4e84b2c55736a81b80be",
      "adbf0427248b4c46a57f93cf0a89aa49",
      "dca0ac4756364da5a35dc3360d1d5ef7",
      "4aa916e5cd314bcba61cc484bbf03628",
      "5d4da791255b499faf41d234925fca5e",
      "0ca13f7c1d9c40c3a9fe48bf0206f8e5",
      "58e07b373ca84442ad62edddda6cebb9",
      "224225886b604f1082425741fa5f49cb",
      "2df3a6767eed4ca19164e311a7a35e69",
      "d8b790a9a26f4759b6f17b82e6fff62b",
      "59472420db50446bb2444871f428c5ef",
      "8f73928cbf9f400aa5d1c3a7c948ff61",
      "ab86cdc307d2426aa7d5f1f132388ada",
      "cafe0cbb956147af851bbdeae9d9222d",
      "773ceb4b0aef42e09a53fc15045d327f",
      "199ff8eb7a1948018a4ebca68408d4dd",
      "db44821dd30f4338882757ae32c2af25",
      "1cda80b32ac94fa68baffe61370094e1",
      "ab3709f71b0140d9a7ed349fdbce91a1",
      "6f806c0dd52545ffb64e72cdbe8d3e18",
      "289ff45a963a47fe95e50436d0900439",
      "13ff98c1e2be4b9895c35d612cb3322d",
      "346fe7eb10ea4fe28544e3db66c747fb",
      "4ad3ea993bfa4006a5fc0f78e78632d6",
      "e5819ed026b54ddf97cee0d748feeb2c",
      "4b08a12892204cbd8febc4637b0c70e1",
      "2f9d871847ec45699135874f43e71e04",
      "e0b76e4bb242452b95a49c932a6bad59",
      "f70fe1b559f344fdb6c6cee0682b45c5",
      "d4f77c4778a548268482c50bfd35d046",
      "a230efd814224896b060b2b2b363a5a4",
      "cc2d0e18299747629b38002618fa0bb1",
      "f8574137dedb4834a75f63a093aa00f2",
      "488077ec23534f12832fa59f80502225",
      "b4b6c225e5da4f2889b9edf8be97f502",
      "c4f0e7a902bb445ab27d481c24eb2c57",
      "11074200cf6246fca781318979f233af",
      "cb66c86599eb41cf828c44c1140e0380",
      "42a3d97cc13148999ddfe617a34d3c21",
      "80abe6ccc6b449fbbf7d45c73cdf8b0d",
      "edb833b2311248b6ad4157f06a141ec1",
      "5fb3b6ffafe94ca7a2b287907ca8275d",
      "2e65e0cdc7364a268645c0be568fc172",
      "5bae8d5b42f74e6c9717da34d4bbe57f",
      "f6869177b22c4f3b815574e812025135",
      "95e6715df3774ccabc9b63b408c9c9ef",
      "454b42d14b26485fb87253e5d079c082",
      "93268d18a27e401db8a89c2955e60de0",
      "cc531b85e32f49b9b11c74805e98ce80",
      "e3286621c7b44db2a4483bec8f23328e",
      "6a31f2ccf2fb4333a4f624153790aa82",
      "a0c71e9477e141e99e2debc3a4d8c6f1",
      "9b692b10af754317a52e176a9758cc69",
      "96a56f72a24248afb7ceef3492524e87",
      "43aa2bba0ff14308a4ec02b35d9c23d9",
      "0578fa13d20944c181e1ebd4345c6887",
      "29f3287c339746b089ac92c480343919",
      "69057e428c274abaa02b56e0555cc3f6",
      "034c437a662e4d03ab2c5d0bd1a89f96",
      "a56f83cee45049cbab354dd91eb58c92",
      "ea404fd31c4149568b8559784f318e8f",
      "e9f8703146cf4198806cebe701afaebc",
      "5c26f35747cb4b86a0f189b1493db6a7",
      "4de575a02ad14b56bc3b0ac835deb479",
      "fb1bc1275d994fb4921db6ac16fccecc",
      "591b7783694145d2b06b48248114aec6",
      "acc8ddd19a754339bfbb2c72ba82b119",
      "ba68ca98f0784ca19807039d0fe4f6c1",
      "a2bcd1b282bb425184e12b9460674ae6",
      "526b37b4df064f95b93d08a1f400b573",
      "4f05c6621e07407c893a4ca466800677",
      "e8980e8c3f094f2f955a233680c43b72",
      "e922d8df0a1546faa4ab8f679d45c9a7",
      "89c51e1b04f64ea68aaa7a4b8ec8297b",
      "d5c98334664049428baad99ca04a3a56",
      "6398e03777b84c5e90d342205976c869",
      "c03a0b8b108c4c3ebd5830a8a059d26f",
      "d75dd5c1b22049ee9392ef51802015be",
      "e9ad012b11ab474a8eb2bef158356f07",
      "00a2ca01e437415cbc800f4c8b385a64",
      "fb04d97066014ea7bbbcd49519affaac",
      "358231e13e824ae9b8b85f0a54b23901",
      "682e9baefb4640abb90619d24bd40541",
      "d6a9a9fafc62437989299f9533623617",
      "eccc0ff6d0d540ecb80cdc58217b4eeb",
      "f0e1a57894b6458488647babc107cdfc",
      "962b7bf87462453797d910193ef63257",
      "7d07a77f4ee54385b494dade3b1009b8",
      "fe37c9d9d4844c009e0509b10fdfa338",
      "48ec8a6cfbe94a909c58dae9301eda01",
      "8f7b3ac02e4047fb888cb9860f330837",
      "4c8363321645432181cfd1005e017aa7",
      "9f2d5370ad0f4e75ae2acb44b79ed222",
      "e1716b039cf24e129776e1b46d033477",
      "539ac09ddd594bedada319995aacb187",
      "225252f8484946bc80a6e4793abfa6b6",
      "cef15a19455e4e40860602bcce32dd7c",
      "789fc2dc4cee411a9142ce38ff717e45",
      "83521b9fa7a8456f99b7aad00747d0e5",
      "3339f0ac8898407e8664363c41f2028d",
      "13447e4a705d411ab41788237d928ea0",
      "7416c1acd31d4916879fad50973747ea",
      "0636369c94cc4352a439c0f329590a8f",
      "87b4d8649c1041a7b1419b5cf675ee64",
      "a39be93b6d904b1ba0ba5efcadd28f4a",
      "49d13e7d54f2417398f438f3aa3dd675",
      "d5d8705664f349e0b391872f57ebd4ca",
      "b04894d9b879424d84445476e2d8abe3",
      "fb046491a829436996b0a518d3dd0179",
      "518edcf2e2ff4a82a915a781194ebc23",
      "11a9cd13a74b4e10a75e2435a32a13a0",
      "a5c61c0a2d6e451e8b178aefca8d49f1",
      "ec8628aea263470683c8aa465d12de16",
      "b756a3d4fc86404aaabde54d792dc3f3",
      "5992dad6b9c24dec873162dbdac34fe0",
      "54f5aaf656a942c29243a81a7b87bb8e",
      "acc6b8ea904749beb42e7c295e7705c0",
      "714e0106191d48889e4326add75c10b2",
      "5f45d401ea59453caa6253e12f971bc5",
      "98d4630a3b944bc792c121ecf68f8133",
      "3c10751b957f4629a190ff86adc047d2",
      "6257a85f14d849e88e695b32a1ffbf4f",
      "02e3ed88cafe4a909da658842782edf6",
      "135e4d75f97a4446b979b528ea752e38",
      "30d3d5c76b47493895bd48fbe8b6979f",
      "6474be72008b43588d83d595a7ac2b31",
      "a5eb02256f6a4413a08f58d1f56c91dd",
      "d56b7216921a4466b0daa82d6de3e724",
      "1db12ec10f1a4825a2c5e224e7e947c6",
      "e706426c2b2b405999bb4454bf5be974",
      "f8bc18a27993492bb8a129f67e1ae5e9",
      "aefdc13a1e334ed89d80f7e2217d2d1b",
      "d8d4fadcfec64e7e9133426c7c9732b8",
      "4f04fd3d49514d1d9846288cda754b87",
      "4eeebf1a8d244f55b9501069f9c29116",
      "bd7d511c5e574671b74d0f0c17f1c76c",
      "af749bff1fab42b79e6c27e1fc7914e7",
      "c3ccdd8ec10a4e03b2f921b299018051",
      "1b412e545a64410e9b8228295cfbe0bb",
      "5593b1ccf0514b369b9ba4cfc4e34dc1",
      "f279a08ef02f444083fb39de83439c18",
      "15705ccc46e049359731b61844b3fe3d",
      "3e5c112145ef4a58aa50e422347ffdc3",
      "b99e18fee86c4a4e90e94594b7eee1d8",
      "67368a9591e34b349cb9960fd899c82b",
      "03b681e22beb47cea07a732d224d1b7e",
      "b10e6b5348c04217aba21100f720a1ae",
      "0ceefbc4ca3245fe97a890eb3d971be8",
      "dbd8e55262fe4b49ab182ef1efd8e09b",
      "f508e68072ea416a93c5d57d8dda8b77",
      "2a4ce2a3f351437b86fc200584252ec2",
      "b7ec9ff9309e40dd9bc085f07d252f92",
      "e302e897d7024d27b6892e308f6c2458",
      "d9e2cbe0c0ab4583b1a757e7a2f840f1",
      "4c4657c2736443cea5eb30f02ccc6655",
      "801c9a8be68044e5aaccb0be7e1484d0",
      "20d3b1a38f34416388af0cee02e9b433",
      "df62f2723c4c49ad9567a9fabb235eb2",
      "da2a525860184cf6afac521784107cb7",
      "50a63c69259844bcb72457b19d42eb86",
      "e016ae56811448989d2989b0a880135f",
      "76106ea0cd2a4607a27ad5a89f9a49f1",
      "f3d98d04c07a4f78a476313f875f342d",
      "1566503bb88f43f9bd3f83f959e1bc3a",
      "754fbb7638b64088bfdf9768584fb1f7",
      "7bca8b53b2a84e83a5798cf190cfb4a1",
      "70e9e8726c9d4d38bc25b7ce424109fc",
      "573fa0e8a7a1443eb33ed654d95589b0",
      "72e66a7a0677457ba144dc19032debeb",
      "085ff6a81d6a4e168d96b6aa19198e47",
      "82d21bbc7e46446d8b65b610a15a2eb0",
      "5bdd35268bca45d3bccc9d13ff7543e7",
      "5ca706c584384863ad88b89f87387dde",
      "df6dec2b7d704dc8893c21779dfccd5e",
      "acefa99a42434f5f92bd1e164911a60f",
      "acd2beaec26042b99ce80552ec619326",
      "93257988c8a5402aab24b5575f39231b",
      "705c0d561b314738846f4d13255253de",
      "139f6b25634c4194916840b0f80f2c1a",
      "13ef0f9e21684c989a446b4638269c06",
      "37ce096fef84486aa1d0605733f70ba6",
      "c78b0edd8b55402394fdd5e51f50d0e8",
      "1757661788e3460aaae92007bee70e69",
      "7ac0e3241b684fdc8496441b7c4a9b82",
      "f309bcac8fd04847ab82c3859eb590d8",
      "7a90fc2c2b254b17aac41378deb6ddf5",
      "d6b6a37703744a26bcb5a32b7945a9f3",
      "9fed84bd46eb4d9394cb372412133970",
      "21a5f941b86e4730a4cd2490a85f379d",
      "07b71264a1b14b2a821155311188e17d",
      "61dee702297b41c2bebc02d9003f15cc",
      "4c4e08244dc14bc39d28083cd8ad2afd",
      "d3237b37c3554f88bc1d5436860cd7aa",
      "c8f7620da1cc4a149e1b5fc349d80f1c",
      "cd2111e58e844d91a5574c53911662e3",
      "a60545f1027d45288cc5dd83e8883e13",
      "4e983b7766b74d89b76839f37cf9798a",
      "8db03d7ddf6b4a6b9159167b50c0cc3d",
      "99d377ae72034ddbb426a4c4ebd458b8",
      "48f88c086d1f4c188879e560aa122f11",
      "819d9f16665348f99c27cc1feaf2bd22",
      "b3df9fdc2f9b489aa38c8a670c54926f",
      "0002ad01b5d3406bb11bc889726c9617",
      "f81c2168a7ea488c80c3369c06fb4c76",
      "2c3e61bd67d847dc945411be8abd9cc1",
      "f5a290d4c55d4691abf2623d6119e228",
      "6e713a01e9d24d6ca85a7995a2cc607a",
      "425b2825d31c4e1f8f93772960257a79",
      "1e16ca75d30d4639ac653be7b15f4cec",
      "7e53241ad96844e4b5db7f5414e44423",
      "b3b526b17fd345e79915e73928e8e9d7",
      "a235a951583340f5bc00727803b0741c",
      "344a6c65d8b24974bcc105557a2ede6e",
      "708917c081bc466ea882538201b90d17",
      "e1440414d32e467c83957f550ebdc996",
      "0e5794b9b37b4b55b26acc1ffdbb7387",
      "f683a6b92fab4b4ba1bef47e398434c2",
      "f2e3c8bac98741d79e8ef0fcbdbec827",
      "33e5e8dddd2c460d8d9d427684b6ec52",
      "f9d7d1af4c1149009f063a9b3ea32d67",
      "4f613c4cb99943d88cc6a6440997518b",
      "b3bcd959f4d04384aa9e5004623d4e51",
      "e831806d10634400b105f0156c627ffa",
      "f43884589e984c6db4746399d451c4ec",
      "936b66c3dee3435bbe4c49766d2c09c2",
      "996cada948554aaaba096e62695955dc",
      "ea44480cc8f849dd9931053e8f2e4b09",
      "86fc767608c84af38a50b0290680d268",
      "22ef17fb25f840fcaf96e8b2a9f175e6",
      "5eb156e79e7b4e18a9d7b8abb1ba4419",
      "29fcd8abf3c44cb996a2ea5204ea78f2",
      "62d12a33e37a4395874636126a2a6f85",
      "737f80d3623445dfa98def5cc08c4e95",
      "c9971b8189b945828d86cf613b7325c6",
      "612ab2c723f74e53b241d0aef6d444db",
      "f3d36dc66fab4ecc9031806ae60f7b5c",
      "904965fd072d4e40922f5cc02481401f",
      "b9961565b8b341d492ec111bf01376f3",
      "93b65aeb6c2c457a98cf2b5f5b0470c8",
      "cbd41f09aa6c4e31abfa5f4e6ef98c98",
      "96cc6d47e0d14ae4b21bf30afa01d04a",
      "9bde9a733c584c0d8033f0905cc362c2",
      "27941e5d123d438d8ac0ca1067dd905d",
      "1416c220802e48a7b204e72f0e272beb",
      "d2116141448d4d61bb1ba4a0c3d21423",
      "05512e651c0b4cd8b7f3748fdbdb3b49",
      "101bb215a525419aa5473df63cbc1aaa",
      "0de07a1325e54eba90878bf76a1465a7",
      "39c38958716546c6a05daec1aa2692b9",
      "ac7b3841ffe24ba8a93dfdf2ea369bb4",
      "9005e502516f4941aafce7424c6f3f58",
      "990296ef405b4f649acb221c723fcef4",
      "00d23e202b734f92815a9895f70ad741",
      "2dc3ae9ee6e3496b9cea57bd25362803",
      "8873a6f729fd4496ba9b450924756520",
      "753a69fc6de04a0399fc46516a56ecfa",
      "c9b0b65ccbdc4c1597b84d3f6eb02cc2",
      "bfbdf92411f6470ca4864c2a06cb4b77",
      "1aa4a36025c041a8987a57b010c5b9d1",
      "1dcb5145f403457aa19acbe86aa8b1be",
      "1f59521931554b1a8f48f2308ed52f46",
      "9d27fd76b6c648afa9878bc0d64e9374",
      "8237015b9f6346cb9e2a38569a80fdb9",
      "7b887d00df6b46349812fe14b70863a5",
      "d806e38c574f4007bde9bab7067b061d",
      "66901bf265e64a28ad0e1996e60a30f7",
      "1a79758b102e4f7385518cee46b8caa8",
      "e4b073bf6ba5481bbbf0a3f5b2f5e1d0",
      "3b3cbc9077a0465b8d454a5358de1a6b",
      "d3ab42d36b114ab5bad652e53dbe3826",
      "c8995dc4c8034e978cc021e2919d1486",
      "2f534c3a94b84592aac66c78d9da7cf8",
      "33bd778d49804c0cb5c7c60687af00b9",
      "80da378bc7404e3fb9304da185287879",
      "344c025f02bd419288d8eb446cdc435a",
      "8414c73cae154ba184f0b0eab4b4134f",
      "b5003e948479463e88a208329b7e9d85",
      "cd3491ba570b43d39d87ead9f4177318",
      "b7c0bd7679664df3a33099e4481fe3ad",
      "72767a15a8344d969595dfbf806c0529",
      "d128fe19292a4035b0565676a42b17a3",
      "b95a1b24906745b28ba564023a37fa4c",
      "473480fd2e0b410b900d3e816f6b7b19",
      "72686ac0beeb4317a7aeaea4900d1844",
      "4eb6da8883a149cfa0c1371f9f58c9d1",
      "8e455a7f9e2d401db4f9b3c9d09e4697",
      "628ec6a1b5d949dbb98195dc8865c639",
      "83a1ecde92d1440d8860a094303fd962",
      "1209774f6658426788220fd8d4fe4769",
      "8aad0cfd39a94d99a11b9b4a105a792c",
      "8c3176d8d06547cfa889b23d2156909e",
      "5b8ac55a2ff5412b8c9be74b5d078c82",
      "0ba992dc7c604ab3b5659b54e02083e8",
      "80c96a2c1b7e4f0aa59bb4e427961fab",
      "26bd19ef38d444bb8c492d213d16ab44",
      "909948186240439db53054b029b4f582",
      "66230aacf95d4a3590daea18770b2118",
      "1f456efb9b3544c89e8cc184a93f93d5",
      "c42d09d0f9874eeba2f81919eaabf18b",
      "03c7ce50ecee44239bdf244df770378c",
      "14a3f65cd799473f96fa5da9e39c9fe3",
      "68dc3ae7272243eaa5838b27aadd6b16",
      "7bf3c192bae748ab8210754df4dc046f",
      "6cd1c018dbed494ba5ee52b9d362311f",
      "3e8cf3eeffe1438dbf6d7379f8f5f325",
      "f3f9ebbff46b49048b086b505745f12f",
      "96f2ccbb0e15413488baf07539efd0ba",
      "b6bb72d4f25444538daee16b1139969f",
      "70481bd0e0bf4cff9400dcb3a7e90f95",
      "f1f24fded5694c8caa5e95d7d5ca0190",
      "12d216f7bfee468b8430f7ea046e164c",
      "e72b40acff104dae8535001917959e25",
      "7a40c00453fa4d07ae73e84f6ca9c0bb",
      "fada90da88d1460e8860f0856451c56b",
      "0fc42fcd7ca94729847a1490a92714a2",
      "712cd4ca83754b4c927bac0aad6406a0",
      "a0d1a5726e2845059a98195e22c9521b",
      "eeeafa2404784cf08c4d530f989beacc",
      "a4a745259443401c9ecf826d601121da",
      "52bfc3fa8a474d0c80a415fb9c5b0266",
      "df791778fd444e2eafed9b6242ff498e",
      "b21be891185148deb4ce7b0d2682e60d",
      "8dd5f878104043318dd63cc7b5cd480a",
      "c20b11654eb8429a94910f88bb4f914a",
      "52668e34d95e4e4e9c410b270a848c72",
      "0c530d50c87c4262bdcc3abfead744e5",
      "e2a968d3b1e04b239b24222be4e2bff0",
      "7da1a71f69754db493f1d42f133bf962",
      "6e25aaf73aaf43d8a72ebd90150f544c",
      "4d4b14ad5f2c4817a368f3b758fd22c5",
      "6415add0176a4d1f83626bbbf5514546",
      "aeba00b6860d42f19f8e3259be3d2950",
      "4fe56a16d13c4559acede103432e5262",
      "28fe79db315d4fdbad69931a22157bf3",
      "ccbf4014be834007b59674f7bdf45476",
      "0ac0c3f7886b4433acadb2171ead83c7",
      "c618bc2001d04918b40b8c99be11b5da",
      "2cdf51adde0d4138a35fedd71ee0470c",
      "a4d247ed1c474fdca4b247825f4359a1",
      "a84742cd07ce487cab5dffd646b6c743",
      "64a0b22686fe4ea6b7f4d823f3e5a5ca",
      "ca38896ee7474dcb90e285a083739c6e",
      "153e91bf045e4297bc9ec64335311036",
      "4e266b2eda5742fdb5edcf1a39d667e9",
      "cd23db7f4ae0432c8838a7618475107a",
      "02908938d9324de8838129506d5a7679",
      "03090f5479994bf681b25f72364010ad",
      "97a6afa071a84152ad65d6fbcd185044",
      "49c5ad683bfc4c0f8ffa5f02cad632a1",
      "06212bd238ee4951a03df67d42f7827a",
      "a29b019260b14734a57ac78f667aee0b",
      "db3b2fb4ae124a3398cd10583ac2b848",
      "cbf6becfb240431d80a7abd47aa297c7",
      "4e6daf09e36646798e489fb8a0064a52",
      "992561d66581425baa5dff6806b5b2df",
      "c7a3c2fef8f74c39a743d2aa65c0d4e0",
      "ca541c1cc2234db3a16985a8a1cd0532",
      "812fd141d7664af08456f89cc288f0f1",
      "dd2bf4d4119e4a37aeff4ec4484683cc",
      "772788225a4c47bf94c4abcb73d92413",
      "06aeac40aa2841028e9b41df65d6ebee",
      "38ef963a505440ac9d0a3192752494fa",
      "721d5c84eb4449d5bcf9c11afb956403",
      "e2a0d1ee68ba4cfb8643549a90776cff",
      "72f21a27fa48423782ecf7a5be7c6ed0",
      "d4548e907e804b8f834cb1f6bc3cccaf",
      "770d9a144dbe4b1e913012e9734ab3be",
      "777a9d4aa02f486a83e09ddb44123a20",
      "ad590ad3f7a242f8a66a2e3c0acfddd4",
      "fb3ebfdc41944fc1b462900a13bb943b",
      "fc824461436445358b7793596c6de44d",
      "ca3fb1a36216475e837b245f523640f2",
      "dd7b1ac6842740ea892ae5ef77f8469d",
      "a4b89275b51c49058c192b69d57f77da",
      "8cef8718a370443397a442df7bbc79bd",
      "0782002192fd4100b7534984680981e8",
      "f47434ac8a8447f69482bbc2c46329f0",
      "8f12a397c5ef48aebf2ab1048c05dcda",
      "69b40665edc4446e9e6c1e72b22d4691",
      "56bd1ac4716e474b82749eb835c90669",
      "0cc83581ac6548e4a1ae4cfdbb4a1aef",
      "1f6f6d480d8e4b1aab2156198e03355b",
      "ca46678a2be0425a91fc8873a141ec9e",
      "d9ee7d59db8c465ca90d222ce1801641",
      "ecb5819d88c140dab0863d3ae93e173d",
      "bb0bc5cade8b471987e00296c1aa9c9e",
      "e3413b3192bf444d9890c44938e1d6c7",
      "1af2c2819ca74c3e8c4f876bf91f64e2",
      "8e642087b1e541f0b94beb7254465c6e",
      "3d9ad67358774c359a9546abdb06dc09",
      "aac951e1a0454d5cbda740456fafbaca",
      "5700c93638b44478aeb50276214e1a9e",
      "a57ffa6c8dee4b6a874a1c9a07ca5ba1",
      "86e2b6df73d04f37b95b4ff115b1ee76",
      "dbb934e74b794cc0b1545e160d29930b",
      "78e546b31ab240b0b0eb2eaa6d657b96",
      "54255bf583054e1897729fd881d3b0dc",
      "f200a378d5d142d8b6ecb5ff07ea4a33",
      "351b5f12eaa1430d9b504314501c5f51",
      "0e1a8f03e81f4eb38f72bfe85e59f2c2",
      "6fa372a24e0248408d5290c815e9dccd",
      "cc2c7479d32d49279c056b8e6cd6df8e",
      "f3160c4862374fa5ae7d955fecb91ee2",
      "ea7aceac57084342a3d5aa4eb8ec294b",
      "3de5a8d93c664d569ca2d60c741dfa81",
      "659a69b6091842e2960aa58279690d7d",
      "be72fd13336148859ba7b95da2c233ef",
      "875bf0bd5de4419384e7ff71b1762adc",
      "a8382d3263d74c5a80ce340509f54c2d",
      "dd755658c289487bb57bb45034c8f65a",
      "3f75840bf47c4bacb95124e7e9fa3fcd",
      "7b085fe608fc4c879139d264016f311c",
      "82384ec7cead48fd855c47512547a6b3",
      "eff6e098d10e4ba8b1c7bf2ee78d6884",
      "e57c143217d64e1299aa312b4c609093",
      "4590d32685f9493b987c2f3c037ea31c",
      "abe9bc2261844596bf632da42a19eb22",
      "859392dd683344efbcf32689ee98ae8b",
      "63b18bb9b221457ca76a9c6a09542ce6",
      "163f1961016e499b83609b8f438faf0e",
      "37b60b1da8eb4016b79588db76bc78b3",
      "cd7fd3b33ce94f57b80fb2f5cbdbf4a7",
      "542cd78cc58a42a58a6e8762d7cc072a",
      "ba8eb8d5b6d64be787921f7d2ac01277",
      "ccd5712c3fb943b9a90672eb800e55a1",
      "3039a3afa3e14730b0c71123c6b20cb7",
      "7faaabb613594b8fa7dcb872487734ae",
      "b630221efb194c2dac687dc07c3a9187",
      "7af754bd89a842f59734b0c01e361607",
      "b00dee27ab4b411b879ccd2961206b97",
      "c5c1e6c173db4b9d970e10c137079f1a",
      "8f0eabda930148fab815d451703340dd",
      "4e3f6d83bf4040eeb61e42c7fcc0918e",
      "517cbeff616f4774a0a470022181de7a",
      "6baa56156f8d4353b5fafc5a6f162a94",
      "d4a0a36b56434ca9a116841c1b0fa1ff",
      "e76e2c01ff18421e878266df04712867",
      "c1e7486deebf441682bd1792098fdd8b",
      "780411838bf043ebb65909ba2fe481b1",
      "d3ed8ee9aad84862973600646dddcc67",
      "fd96d6032bc14eb88f4b18d34e3a5e5e",
      "f50dda696f8e46ea924e3eb15a4f774c",
      "a90ee3ae54334f01a91876fcfcec9b9f",
      "cf6d35ba4cb640ceb9afa07507f7e685",
      "3d43e7d0268f4647815e768811284fd7",
      "d8f392023d4147f695baf853db3f4f75",
      "d1f63e0940b6494eaeee38a7e8a0114a",
      "0874577b4a6f4995a00b485c50c0232f",
      "b0c1398f78714439bc9ed6aed4ef5b49",
      "8db3bca1fcd34ce19603ad79f444187a",
      "1c212af4b4c34a0a8eea5f40e173c338",
      "df77a17c813e404bb51a3b0b4af47cb3",
      "d18cddaa69084300a80d967ec5c0f765",
      "7b9d23f877294062ac3b7e6da4e23bc7",
      "ac71d056f46240a68a0716589e946383",
      "93e1962499b445998bdbd0a91cc0866b",
      "cda2001a4b0e48eb9546908a6c7bf72e",
      "f557b238e3a7416b8f3255a99e53dd62",
      "5c557f887dec49d3bb585aa7c772941c",
      "f5680b66abba476d8453d09cea5ce5fc",
      "a35f598d2e124fa5ac1a59cfce0d14b3",
      "0721f3579fa047b7938ca004b7c72d78",
      "ee353ada81474c0ab47ffe3f99ebd109",
      "f991311844e84814911a58aece69dc36",
      "a63de95559c144b9a3df1a9811aa7833",
      "2c9c458cf9324d2fbc64c6026cbc5e59",
      "1bd8139b3b0a4b0fb6ab6494c13cac11",
      "ee7ff9a02ff14c318cae0bad15ef7f62",
      "01bfc819850a41748d183ab98787e8ad",
      "a5633c4c52704cc18da8995bb034e4a7",
      "c89d0ee7c4b04c53914603bb442d418a",
      "e42ac57992304056abf688e26da2f6a7",
      "cd30d55e69534d789ba6c1d64c74f2ed",
      "8bec2ccf241543b4a292c8257aaaf467",
      "4e2cd8ac03e04527a01e32244e3a1b98",
      "bb5c7a600b5c41fbb6db1f27a547e324",
      "d11fc2f3e1b64b33932ec5433e08ef37",
      "8772e82b8b3f48a9801a16994141782c",
      "10a82195be9e4a35b789e6e484bb7b17",
      "11ef4fe0377249859ec9c3dcde71517a",
      "825a51bd0f7448a0867a58c97e0eb471",
      "0a31b0c00543455892aed599b5b7b7de",
      "7e7fe3dbabd04e269fac1c4902cf7abc",
      "c95803292b504303b824285df67cf642",
      "6ebbcf202c9b4da2880c5af665873f79",
      "03f3657e6a4d414cbb00516445d8c3db",
      "298310dcb12b4413bd6424f4e4e66c63",
      "0b6f35df6ca44905b288e63b74de6dd5",
      "9aa4e811ad8b425393cc5795e768f360",
      "763665fa5d0b403fb770e2f8c773ae2b",
      "3e16328b80744a48b037b3cc1d830d4e",
      "7b3bb447f28b440e898a863c96b5ad4f",
      "20309839cca342489fa25b1e1f2145ee",
      "511a0e730a904d3191f8f8cecf22d605",
      "32535712607d48efb5e3bf1fac02bae9",
      "9e126ec9af9549308305957d43acb538",
      "afb3635bf635485a897ff6a70e0a9989",
      "68bcdf6e0c174132855f5b419c61a8a0",
      "277cfed41eb242b2877f605a282d2500",
      "2d819c157f7b46bf981a678c6160d76d",
      "f6daca984490425abe44420ee81b84d1",
      "27b76406cf6b46ae92bf45cfd8ad386f",
      "98e74f6df6224ce0a343e78dbcc7abe0",
      "1a701f057e75453e8b799f96d58979d3",
      "9c8cd3028759482086ff6dcc180f5d0f",
      "20eb23c211504e5b9861f6130d7bf0d4",
      "bd00099d94d0412ab62645d9af454614",
      "5168bba594cf4f42b1aaf133d4968107",
      "54bdf35ec377477f903ee3539fefd51b",
      "939e086f64f44859a00384d2c21cefc0",
      "697da9fd1a564e358858988793d6f6df",
      "116d33531c13438f8fd66152b4f7b8e2",
      "47aa7c6b927a4ae1862b74d0465c6438",
      "f6bd37ca6d27445bb30d706d0dd5c3d3",
      "3507219639ec46948e825d4bd9526064",
      "589346e470da4fce9ce3fa8b4786f091",
      "971f95f965fd4e7ca0de95c3e148df0b",
      "2fdb0bf65b8c472ca733bcfcb0f093b3",
      "e273f7ea82b64c7599b1ce1fcbb0a9cf",
      "6afb1ab2a92d44cca0cd81ecfccf19a4",
      "547f746f7b124bd4867cd88964047abd",
      "f264f76d443344048140a5c74e27e396",
      "a929e7608548455490fd9f77ab57ead8",
      "70e49ac64e674295b0b2d164bc4e5644",
      "6069a70a84004e3886304fcb8b718c33",
      "5f27c17b274747a4b1fa9c180fbad336",
      "d16e9a7a60e94aa3ab70e49f709b7c0b",
      "7bd515a583f54ac981c2cd25b10d488e",
      "b90c4654cfa1497a9a95cc869259cbd0",
      "85cd626ea397454dbee9a25391a1e3e4",
      "1c4048e0bd8b4ae78fc060a7fb2f22eb",
      "385551c52feb482192b37230fc1bd64c",
      "05590bd7609443a18291877960363c79",
      "08e4b58e76b04794b1eec5d115a5883d",
      "2772882d51d540d1a742b30449895f42",
      "6e2c1b9f6146482fa5fdc8ab225e00ad",
      "53af6e6fae08429b8bb966d4374f5cc4",
      "200af4f4970a4fea865ba1eb164365d5",
      "3fc0fc81d4b243028f06ee4c6bd7225f",
      "97574cfee2c94bc985289f2aa848800d",
      "283f3cb8642444e0bdac0d29e65301b1",
      "ffe25d676e394a8bad76eba41c4a3e24",
      "77b11dbca2c74fba8b833901692365bb",
      "88594aed85384ca188a4055d3aabd7db",
      "2992ab0ffc8444429502677f7663f901",
      "89c8270e63cf4c3787a1dad136f892dd",
      "487846d5d89a4d87a99f21966c3e8987",
      "ace606cddaff439c819bc1b6269ad9db",
      "1a270ab845ec43d9b5f27b2d18f69fd3",
      "6faad1c10a79478f8273984f20c7faf1",
      "440fccd690894fba80bc8fdc4113448d",
      "3ba572de76d24bf9987ca02797d1acb1",
      "ac499119d6fe401a8eb584ed3e58bd6a",
      "636ba454834b479a867c962292acea39",
      "e7d424d5128f439499f1f0fb1c4be93c",
      "74155867bb7b406489d8a71de094cfea",
      "2cba60f6dcd747c590fb4999d12d62dd",
      "fdaae3d10c174458a65997ba108472d8",
      "78cee800d4ad41d0ad1a85a723c747d2",
      "5f80f32b13764afba8a61f14711a7a7b",
      "5341ffd1b207431ab9475863e79654c7",
      "43e9816bada441f18c8127b49f5ae84e",
      "0009115d51594c03b5806b4b627d84ab",
      "16b37b8449a5481cb8e72d87ed953684",
      "f24a1ffec9904ce08ad6c3b67882633e",
      "7676676ede6749bfbd88ed4c1cce55f3",
      "40bccf70e4ef4521a7b10f953fe784b2",
      "93b2028f701a476dae1b3053b37eca57",
      "4290b03d0c1c4bf5b4a66220c960faed",
      "63e8d8ca4f354795ac3ecd8c1e216f18",
      "c70cf3cf23924b31a7f3bc45644ccbea",
      "dbea77ddaae24058bb3eb0c197ad3fe0",
      "1ef4e03fbc024556ae31a139f3b4f624",
      "2d194cfd2f534d9aa5a91e21e561f13b",
      "aa7bcd52cd6a4c6a9c9b1f9b316fa2ac",
      "4edd8a9c59f84f8ea7eb7d153e399196",
      "f096ce87108d43299e68675af66c996e",
      "f0d40c2d1111402da5ed1087100e6b3f",
      "75251a9573a743829ba4ebba9e8c6336",
      "f2a893b17bd846e09ef3f4679e98110b",
      "49fd465a413f4e2fa2def63ff26808e0",
      "16f9f241f6ee4750ad8c423894c6f2d5",
      "2f953d447c1a41adb0911c2d70fc384d",
      "ecd62fe52109455095b4e8b73362dc18",
      "e9f6a3d0d0424bd9949fec646d3006a2",
      "a849cd2ae42e4615aa13a80b01152008",
      "3ba8d3826caf4381a11c538e91d52386",
      "397aee4367fc417d8cbda741b48a4684",
      "1d7659e1f5bf42c39e7bd211976541c6",
      "f29c421b0a944a15957a76d80f6586de",
      "587ee620424c40cbb6c2f78bed8b842a",
      "08b1cdc6e81b4f858cd573c52d6cd8db",
      "51d82a2737764d879d674d55f5191aa4",
      "153f1c5ae76f493db631fdbd90e30da5",
      "48bd8c714de8400cb554d77d2bdd85aa",
      "fb56ea298fa0410c9bb78eef9867bb76",
      "9f738b1244a54a8a8f3cdea38819c6e8",
      "ab95d3e037d04859b0e5a74554387eff",
      "8b7cdda64ff24b39bd71c6d7b73a105e",
      "778c0209f4be4eccbdbe1c4b10f9590a",
      "691ea52f0c3942f79a5b09f78ed10f46",
      "9573d54611374d4bb508c837775dae46",
      "397a01ff50334a92bfe9f3f017b4e45b",
      "6d1de22254af493e8ac3d5622f56c122",
      "1257ccd520be46cbb030c2ea6d482b18",
      "11bfff0e4d884ac8bcadcd8e04823e75",
      "45ed8f116f7949dcb2ad7a1b81e34559",
      "fb6e888de8e14eb69aec7a172bc2d500",
      "324fdc798f8b49f0aadfc3414fccca20",
      "a00b24e097e0450baec1b2315f301d33",
      "8818926fbc23468ba949eb81857f7d11",
      "717e1c3ab8c14ca0a89467dbd0709533",
      "2a4616ddbfda46bdb4e8f7934bdd4763",
      "75f3a54db3074d659f4eb465c6c292f7",
      "288ce24a40c84bfc8ba8c08bcb535a78",
      "388e8649de1041e7b571191614bf441d",
      "7200404025114ec79f0c6fd77b6e841a",
      "9ce52e5d85ef4a2bb84c643cb3ae0fbf",
      "3499e20814844c0893bba510332e274d",
      "ad97356e6aa948b984af940c446c3af4",
      "7b7eecff11124d03865e7b71f3f17f31",
      "3f12ebd196e14adbba62b66bb966f4c6",
      "ed3acdd21e304b9c89e98032fd486297",
      "31ab3cd136894d58b9975f268627c804",
      "0c72111ab0e04938ae3a1992b6011114",
      "4d0013d5c04d4eafaffca56e4b7f96d5",
      "75d841da08f2440caf89f3e2b09ebd2c",
      "5ca8c353776941189b26d74300d79f14",
      "ecf70211c6634cb08bc11dbe8874fc97",
      "081b970ab2a240948e9e564f2029762b",
      "256303e11aef48258a4a9b86e89daba8",
      "31907a17b57d471b957610033bbe0249",
      "da1e6930142a4c83b0d9ca925e55523b",
      "d124f0da82dc4a76b828dc7497c7613c",
      "d1ce2cfb892740de9c24974bf79c0a6b",
      "9a52fc9447544a5ea10a0a869eb2b3fe",
      "796296ec93004edd9c85f7df63cfc82b",
      "a8eb71936a4043fe9803a65bf2ba7596",
      "65b54e0e5fee43abbd3a1e46ae5cb4ce",
      "73c7dd3c4a3a47619cf679c78c29acad",
      "3fdf38f1483346889e5af47560613985",
      "685cd2a7fd7946be9816751297da0f4a",
      "2a6a20eb72a343b3b3be988d60b20003",
      "1cad052e7d6040df852bfc36d2b36b41",
      "6e94c58b24394689b60f37bb9f6f31f2",
      "90d5b424b64d4fefb8ab0ae7f045c577",
      "09ad46ebfdb24242b3239aaa5d68cee4",
      "c742a8b456b14987aa15deca1b099d08",
      "330b45f5a6e94cdd9201197ba08bdfc0",
      "5d4d424ddb0b4a2a9458749aa5299628",
      "34a0581296de40e19154e8feb60f5a23",
      "529ac5b0ade54456a1d3c4180d1ddee9",
      "fef5a9e2eab04c7a8e7dbdd095e0fadb",
      "e704e4eb8cea49e9a91c9607b7b918f1",
      "22c1ad32b7774c04bfa35b6ce35b1be7",
      "8523d0f95c8247adaabc0711718447d6",
      "db2ffd730ca94efe9b5b3dce85918001",
      "5ee5468204cf4d47bb8bad19317e4cd8",
      "40cf40c9e5b74bff81686d007752d949",
      "a6d020d6cb274cf4aa2fac9a39a87a4b",
      "85781e94c4b94fbf8ada7d90c1f3eba9",
      "22c6df52bbce4a2d9c620d7582d33490",
      "ec85b87ed596455e9379c80032d9d454",
      "a5f98286b0fd44b987b8f210883c6b38",
      "09ee837a261e4545a55a71fd6ccd31bc",
      "7f7b395621064c3e844f0800730c5e6c",
      "8a86945a476f464c9eff5af7ddd9ba94",
      "62c34c1a2e934ce7b68b117c55c6f506",
      "36349c98815d4efaa66a5d1b538a76cc",
      "1f32d5ee28244044aeeaf81bb260a2f1",
      "32053622d6df4b37a9f40bd1dfaf91b0",
      "0ef32ca43ef1400ab77088bfaa631c20",
      "d53ad3855106427c85f39a866bd4dc38",
      "164f201011314a7dbd31331bc1724911",
      "5d8c9d744b2d42eca76504802f688917",
      "43c34803f3254e3d94a077b3bf0ba66b",
      "d0ed5d0631254452bb7f6ccb32ae3128",
      "257733d0e45f4ac0b5d69ae6b4b6b57b",
      "cfc6b14499da47bda056748007dd0cad",
      "5caddacfc2834acab983abd28f53308b",
      "56704cca88644980947fbf2bb236c410",
      "e4603407280c465ca994f9383e8ff6fc",
      "7c1aaeae7de349e284c99ca6cfb6883d",
      "0a4c7a8ae30548ba9b708af66e857bcd",
      "cf7dcdeffee6416c9b85710203948bd8",
      "cdfd7a94cbde4313be61facfd882a1a3",
      "cb6ddabcbc964f00a3ccc51c205e0a7b",
      "0798e0870f0e4d6c9c140a91d90cb8da",
      "4802723ed3f34766bd06ba72e8b96ff4",
      "b80286bba44f4b78b6edad1149fd0435",
      "2a2f1dd43f8a4903ba05adcb740d5354",
      "37fda9337b034b4ba50d7c1a2feed269",
      "833c5ca2007a4fc988038150dc5e7efa",
      "d85bb184e1d94622b6312e95a520e3a6",
      "34312f86c1b14e8a8e6af2cc825e06f7",
      "17db5a3f8cb744be91f05fbd5c9de6c0",
      "9ad3658b0aa942cfa9c4536ebea22103",
      "713dfdb5471f423a9196eb5acf21485d",
      "013cbef3a55d4b89b51f2b6123caa176",
      "1c9d34291588497db60979f1a1d63073",
      "9cfabd56b7db487bac4003b87f3c154e",
      "f9ea70fca1be473386b4472f6195f287",
      "a9f220a93b56456fa55dca139a732ec3",
      "08c2ce34a85b452da9138e23a26099bb",
      "58b1ff8ada164ac4a1a8cc04b89b8f6d",
      "68abfb325c4e43a3b9552043487ff3f5",
      "accb233996044e8d823f9913014d4d39",
      "9888e7b0c4524ca88e157eff6c74707b",
      "06287dda54764203b7fe7645986078ac",
      "3de3df8210eb480a8b44a28605f8c878",
      "932d514dcce944efa5b762325a1d1564",
      "979e6c704b3049f9b9fc0482648c8402",
      "06867f548d3146c0aa0f105eeebf3310",
      "91ffb743864f4de999506f3481e97b66",
      "ed1803b86a5e4ee787048fa1006ed62d",
      "23983c0113cf4b7f8c3f149760e77d96",
      "a91776a9bf2849e5b3a45dfa3772eff3",
      "6600eff72b044c3e8cb545a54c0c4436",
      "198d098396e74371b8ff9e7b710ecc24",
      "bd44b106526b4eb3891aba8c77fe1dec",
      "3ab8b8baba5f4f6fa88d4868c72ccd67",
      "8943b3f211e04e8a9e8cdce94af7d73b",
      "a44c04100b614f64b5e0e55419f31b92",
      "0e4c70ba50a34581a118ec2ec8101ca6",
      "661e75f017ac44738ec2bd4a1520d1fe",
      "fcda98d4de66453c8c16c889f1fd6cd4",
      "d2f685191aef41baae6033c3ada84eb2",
      "0da34607e9454355945d345f16134a43",
      "569c3e94715d47589cc6b8e52c10c64e",
      "e21153877497457ebaa22a7e2a4e77fc",
      "bc3ff7b8b99b4eee979fb80ebf2fb15e",
      "7561218f19414118b0e6ca187e7feb8a",
      "01e724cfc2ed48edb037e93891090a5e",
      "dd1569132743481ea17fc5d3c9868355",
      "2f1d1f2eec9c4bb2ac25fd3bb904c912",
      "5cd39ab64a79495c9ec3f7faec9b7e80",
      "60bb6b11062f41138d96cbdd7e74ccc1",
      "9e22793bbc3040678be3dc837f74d2b6",
      "4d9d752267a746e585227c2adf67ebe9",
      "aacd78db47fe44269b1b018742cb9562",
      "56f915a0e8844194bb5b171bd06d972f",
      "213e508dcfe649cd9e2cfcb21460b28f",
      "4744343119964267b358c374fa893d28",
      "df469f97bf03451faf51d3120eac9c96",
      "08f402d925064cee99b280fc84b5ca2a",
      "3ba773098a3d49f682f7351e18821327",
      "03e8586f4c0046cb853df6493676dc76",
      "cee143acedae4b2dab75abe8767cb02d",
      "0ed6ed7653b74c189e0eb2219720f247",
      "48adb034a5ab4aadb2fbb4658c90b5c8",
      "cf033624eef74d799c8321a2bf6ac68b",
      "b665baae3bfb4f63b17bd5fc9f5e80aa",
      "2d6a06ab60714a3aa4c48474b6b0f0e7",
      "676355067c3c441c8f6ca70e6fc9734e",
      "d1b219ab330346cbb314b5750bd36eb3",
      "0610d96d86874bd2b5fd12eb2ac41186",
      "029bc85342604fde9a81498b5e23aae0",
      "62faa6a44c6840888f9be292a94b2d91",
      "0471c57bff16459ca684c5260b9de0f8",
      "aa75f5e0db8e418f8eda6780da992f70",
      "a3588497ac9f475f830a07596a0776af",
      "53af4f92d21f446abb703283ac54232f",
      "4b80464da6ad48eaba81d448e6e603ea",
      "31912478ae4540ac9a0a0c6155c7f07c",
      "2752b1fa5c554c849276718913f3ed71",
      "ba01b4dbf5734c7fa4921a5721edc968",
      "49380a43ad284952bbb3449cd02fe033",
      "14fafdc4f0b4406a8d5fbf1a4bb23351",
      "16fb35fa12194bb39ad7ac7f353de482",
      "ee1c7fa7ed6e4eacbe35916800ed5eeb",
      "1240c6b52e3e4220af6c5e156b5455ad"
     ]
    },
    "id": "XGLThxZk2FmR",
    "outputId": "d2b067ff-ad55-4557-b15f-a1792f064379"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7472cb96a6b41f6a19597a3a0a28bae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b79ec80393f44f7fb04e04ecb9486f27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cbd1bb81bb446b8938c95e96f5770df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23d50f151279477fa182dfa6c05924d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision 4c53496 (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd6777287abf4470a03a1c327546a800",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/998 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f53ef7e4c8bc4affbc1e26dd13bf21fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.33G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f469e5720ef94c01aa7e0147e3903694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/60.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3327841f45a34bf4854aa6cd556d14b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 564e9b5 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9000deb57f0f4f65a9793fc3eb1e70ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/473 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a81273afc74402fbb1eac71c7d2f941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/261M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "349db094cc7a466b99419d823d07b944",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20377189c29746628850c3dcf4f962f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c55fcedf481244069685d041f4c369d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "No model was supplied, defaulted to openai-community/gpt2 and revision 607a30d (https://huggingface.co/openai-community/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3d8ece3cfa542ac8c13b0dd62f79c28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5865db0a6aaa43b8bcd452e0fd0f89fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b50cb258f2a4326a05c7c31450b82b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a90fa479f5d453f8829bfb328006506",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecc8a35a872b45a8b528dbccdab23271",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2def23cb89bd4a00a19a92cac6e9afc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bf997689d024d6a81b0a771711fd67f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8577660079184297bcfa149efce52920",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b5777f60b7548a1ad5278596f4308a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1fe122408c542b8a28c2e967d421562",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "658d91be94064382bf36fc8be0df0641",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "627b3bc7049845beb759dc578bf43bc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53b28a36dc9b4374b7e46166821186c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a37b7c370f342bd97b706fc9997f845",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f394f808c084b7eb8e8a20fabf44c00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/301M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7af971e2ae5e4e08ae9baffcaf402c41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f46dfdb8575439c8cd563df3cd5d1a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/42.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0c693df1c22449f833f66208a4d5feb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/301M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e074f4705a64a4db48230d03290f995",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "source.spm:   0%|          | 0.00/778k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b5f69d4366b4e71b5fe1211788c580f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "target.spm:   0%|          | 0.00/802k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72b9fc0c67bb41b9ad731c43139f2edd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
      "Device set to use cuda:0\n",
      "No model was supplied, defaulted to google-t5/t5-base and revision a9723ea (https://huggingface.co/google-t5/t5-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "382d2cba007f415ea957b526a2c56c4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adbf0427248b4c46a57f93cf0a89aa49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab86cdc307d2426aa7d5f1f132388ada",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ad3ea993bfa4006a5fc0f78e78632d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4b6c225e5da4f2889b9edf8be97f502",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "No model was supplied, defaulted to distilbert/distilroberta-base and revision fb53ab8 (https://huggingface.co/distilbert/distilroberta-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95e6715df3774ccabc9b63b408c9c9ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/480 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29f3287c339746b089ac92c480343919",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/331M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert/distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba68ca98f0784ca19807039d0fe4f6c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9ad012b11ab474a8eb2bef158356f07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48ec8a6cfbe94a909c58dae9301eda01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13447e4a705d411ab41788237d928ea0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "No model was supplied, defaulted to distilbert/distilbert-base-cased and revision 6ea8117 (https://huggingface.co/distilbert/distilbert-base-cased).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5c61c0a2d6e451e8b178aefca8d49f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/465 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02e3ed88cafe4a909da658842782edf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/263M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f04fd3d49514d1d9846288cda754b87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67368a9591e34b349cb9960fd899c82b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "801c9a8be68044e5aaccb0be7e1484d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "No model was supplied, defaulted to google/vit-base-patch16-224 and revision 3f49326 (https://huggingface.co/google/vit-base-patch16-224).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70e9e8726c9d4d38bc25b7ce424109fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "705c0d561b314738846f4d13255253de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21a5f941b86e4730a4cd2490a85f379d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/160 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n",
      "Device set to use cuda:0\n",
      "No model was supplied, defaulted to facebook/detr-resnet-50 and revision 1d5f47b (https://huggingface.co/facebook/detr-resnet-50).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48f88c086d1f4c188879e560aa122f11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3b526b17fd345e79915e73928e8e9d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/167M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3bcd959f4d04384aa9e5004623d4e51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/102M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.0.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.0.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.0.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.0.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.0.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.0.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.0.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.0.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.0.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.0.downsample.0.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.0.downsample.1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.0.downsample.1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.1.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.1.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.1.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.1.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.1.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.1.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.1.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.1.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.1.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.2.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.2.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.2.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.2.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.2.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.2.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.2.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.2.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer1.2.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.0.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.0.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.0.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.0.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.0.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.0.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.0.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.0.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.0.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.0.downsample.0.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.0.downsample.1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.0.downsample.1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.1.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.1.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.1.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.1.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.1.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.1.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.1.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.1.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.1.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.2.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.2.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.2.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.2.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.2.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.2.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.2.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.2.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.2.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.3.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.3.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.3.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.3.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.3.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.3.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.3.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.3.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer2.3.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.0.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.0.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.0.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.0.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.0.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.0.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.0.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.0.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.0.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.0.downsample.0.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.0.downsample.1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.0.downsample.1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.1.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.1.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.1.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.1.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.1.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.1.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.1.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.1.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.1.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.2.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.2.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.2.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.2.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.2.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.2.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.2.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.2.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.2.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.3.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.3.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.3.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.3.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.3.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.3.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.3.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.3.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.3.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.4.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.4.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.4.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.4.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.4.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.4.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.4.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.4.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.4.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.5.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.5.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.5.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.5.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.5.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.5.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.5.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.5.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer3.5.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.0.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.0.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.0.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.0.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.0.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.0.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.0.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.0.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.0.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.0.downsample.0.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.0.downsample.1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.0.downsample.1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.1.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.1.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.1.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.1.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.1.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.1.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.1.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.1.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.1.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.2.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.2.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.2.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.2.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.2.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.2.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.2.conv3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.2.bn3.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:2397: UserWarning: for layer4.2.bn3.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
      "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "737f80d3623445dfa98def5cc08c4e95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/290 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "Device set to use cuda:0\n",
      "No model was supplied, defaulted to facebook/detr-resnet-50-panoptic and revision d53b52a (https://huggingface.co/facebook/detr-resnet-50-panoptic).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1416c220802e48a7b204e72f0e272beb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8873a6f729fd4496ba9b450924756520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/172M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/detr-resnet-50-panoptic were not used when initializing DetrForSegmentation: ['detr.model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'detr.model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'detr.model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'detr.model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
      "- This IS expected if you are initializing DetrForSegmentation from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DetrForSegmentation from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66901bf265e64a28ad0e1996e60a30f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/289 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "No model was supplied, defaulted to facebook/wav2vec2-base-960h and revision 22aad52 (https://huggingface.co/facebook/wav2vec2-base-960h).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5003e948479463e88a208329b7e9d85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83a1ecde92d1440d8860a094303fd962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/172M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c42d09d0f9874eeba2f81919eaabf18b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/378M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1f24fded5694c8caa5e95d7d5ca0190",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/163 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df791778fd444e2eafed9b6242ff498e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/291 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeba00b6860d42f19f8e3259be3d2950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "153e91bf045e4297bc9ec64335311036",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/159 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "No model was supplied, defaulted to suno/bark-small and revision 1dbd7a1 (https://huggingface.co/suno/bark-small).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e6daf09e36646798e489fb8a0064a52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72f21a27fa48423782ecf7a5be7c6ed0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.68G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0782002192fd4100b7534984680981e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.68G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3413b3192bf444d9890c44938e1d6c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f200a378d5d142d8b6ecb5ff07ea4a33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/353 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8382d3263d74c5a80ce340509f54c2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "163f1961016e499b83609b8f438faf0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5c1e6c173db4b9d970e10c137079f1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "No model was supplied, defaulted to ydshieh/vit-gpt2-coco-en and revision 5bebf1e (https://huggingface.co/ydshieh/vit-gpt2-coco-en).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f50dda696f8e46ea924e3eb15a4f774c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/models/auto/modeling_auto.py:2199: FutureWarning: The class `AutoModelForVision2Seq` is deprecated and will be removed in v5.0. Please use `AutoModelForImageTextToText` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d18cddaa69084300a80d967ec5c0f765",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/982M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f991311844e84814911a58aece69dc36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/982M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e2cd8ac03e04527a01e32244e3a1b98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/236 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03f3657e6a4d414cbb00516445d8c3db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afb3635bf635485a897ff6a70e0a9989",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5168bba594cf4f42b1aaf133d4968107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e273f7ea82b64c7599b1ce1fcbb0a9cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/120 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85cd626ea397454dbee9a25391a1e3e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/211 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "283f3cb8642444e0bdac0d29e65301b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ba572de76d24bf9987ca02797d1acb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/470M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0009115d51594c03b5806b4b627d84ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/320 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d194cfd2f534d9aa5a91e21e561f13b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9f6a3d0d0424bd9949fec646d3006a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb56ea298fa0410c9bb78eef9867bb76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/470M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45ed8f116f7949dcb2ad7a1b81e34559",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ce52e5d85ef4a2bb84c643cb3ae0fbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/251 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "No model was supplied, defaulted to google/tapas-base-finetuned-wtq and revision e3dde19 (https://huggingface.co/google/tapas-base-finetuned-wtq).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecf70211c6634cb08bc11dbe8874fc97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TAPAS models are not usable since `tensorflow_probability` can't be loaded. It seems you have `tensorflow_probability` installed with the wrong tensorflow version. Please try to reinstall it following the instructions here: https://github.com/tensorflow/probability.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73c7dd3c4a3a47619cf679c78c29acad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/443M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34a0581296de40e19154e8feb60f5a23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/490 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22c6df52bbce4a2d9c620d7582d33490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/443M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d53ad3855106427c85f39a866bd4dc38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a4c7a8ae30548ba9b708af66e857bcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/154 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "No model was supplied, defaulted to impira/layoutlm-document-qa and revision beed3c4 (https://huggingface.co/impira/layoutlm-document-qa).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34312f86c1b14e8a8e6af2cc825e06f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/789 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68abfb325c4e43a3b9552043487ff3f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/511M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a91776a9bf2849e5b3a45dfa3772eff3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/315 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0da34607e9454355945d345f16134a43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d9d752267a746e585227c2adf67ebe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48adb034a5ab4aadb2fbb4658c90b5c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3588497ac9f475f830a07596a0776af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\n3.Time Series Forecasting: Predicting future values in the series data .\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "#----------------------------------------------------#\n",
    "#                    NLP Tasks                       #\n",
    "#----------------------------------------------------#\n",
    "'''\n",
    "1.Text Classification: Assinging a category to a piece of text.\n",
    "Sentiment Analysis\n",
    "Topic Classification\n",
    "Spam Detection '''\n",
    "classifier = pipeline(\"text-classification\")\n",
    "\n",
    "'''\n",
    "2.Text Classification: Assinging  labels to individual tokens in a sequence.\n",
    "Named Entity Recognition (NER)\n",
    "Part-of-Speech Tagging  '''\n",
    "\n",
    "token_classifier = pipeline(\"token-classification\")\n",
    "\n",
    "'''\n",
    "3.Question Answering : Extracting as answer from a given context based on a question.\n",
    "'''\n",
    "question_answering = pipeline(\"question-answering\")\n",
    "\n",
    "'''\n",
    "4.Text Generation : Generating text based on a given prompt.\n",
    "Language Modeling\n",
    "Story Generation\n",
    "\n",
    "'''\n",
    "\n",
    "text_generation = pipeline(\"text-generation\")\n",
    "\n",
    "'''\n",
    "5.Summerization : Condensing long documents into shorter summaries\n",
    "'''\n",
    "\n",
    "summerizer = pipeline(\"summarization\")\n",
    "\n",
    "'''\n",
    "6.Translation : Converting text from one language to another.\n",
    "'''\n",
    "\n",
    "translation = pipeline(\"translation\",model=\"Helsinki-NLP/opus-mt-en-fr\")\n",
    "\n",
    "'''\n",
    "7.Text2Text Generation : General-purpose text transformation , including summerization and translation.\n",
    "'''\n",
    "\n",
    "text2text_generation = pipeline(\"text2text-generation\")\n",
    "\n",
    "'''\n",
    "8.Fill-Mask : predicting the masked token in a sequence.\n",
    "'''\n",
    "\n",
    "fill_mask = pipeline(\"fill-mask\")\n",
    "\n",
    "'''\n",
    "9.Feature Extraction : Extracting hiddenn states or features from text.\n",
    "'''\n",
    "feature_extraction = pipeline(\"feature-extraction\")\n",
    "\n",
    "\n",
    "#----------------------------------------------------#\n",
    "#               Computer Vision Tasks                #\n",
    "#----------------------------------------------------#\n",
    "\n",
    "'''\n",
    "1.Image Classification : classifying the main content of an image.\n",
    "'''\n",
    "image_classifier = pipeline(\"image-classification\")\n",
    "\n",
    "'''\n",
    "2.Object Detection : Identifying and localizing objects in an image.\n",
    "'''\n",
    "object_detector = pipeline(\"object-detection\")\n",
    "\n",
    "'''\n",
    "3.Image Segmentation : Assigning a label to each pixel in an image.\n",
    "'''\n",
    "image_segmenter = pipeline(\"image-segmentation\")\n",
    "\n",
    "\n",
    "#----------------------------------------------------#\n",
    "#              Speech Processing Tasks               #\n",
    "#----------------------------------------------------#\n",
    "\n",
    "'''\n",
    "1.utomatic Speech Recognition (ASR) : Converting spoken language into text.\n",
    "'''\n",
    "speech_recognizer = pipeline(\"automatic-speech-recognition\")\n",
    "\n",
    "'''\n",
    "2.Text-to-Speech (TTS) : Converting text into spoken language.\n",
    "'''\n",
    "text_to_speech = pipeline(\"text-to-speech\")\n",
    "\n",
    "'''\n",
    "3.Speech Translation : Translating spoken language from one language to another.\n",
    "4.Audio Classfication : Classifying audio signals into predefined categories.\n",
    "'''\n",
    "\n",
    "#----------------------------------------------------#\n",
    "#                 Multimodal Tasks                   #\n",
    "#----------------------------------------------------#\n",
    "\n",
    "'''\n",
    "1.Image Captioning: Generating a textual description of an image.\n",
    "'''\n",
    "image_captioner = pipeline(\"image-to-text\")\n",
    "\n",
    "'''\n",
    "2.Visual Question Answering : Answering questions about the content of an image.\n",
    "'''\n",
    "visual_question_answerer = pipeline(\"visual-question-answering\")\n",
    "#----------------------------------------------------#\n",
    "#                    other Tasks                     #\n",
    "#----------------------------------------------------#\n",
    "'''\n",
    "1. Table Questioning Answering : Answering questions based on tabular data.\n",
    "'''\n",
    "table_qa=pipeline(\"table-question-answering\")\n",
    "'''\n",
    "2.Document Question Answering : Extracting answers from documents like PDFs.\n",
    "'''\n",
    "doc_qa=pipeline(\"document-question-answering\")\n",
    "'''\n",
    "3.Time Series Forecasting: Predicting future values in the series data .\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 436
    },
    "id": "mpGcy_IP2oWC",
    "outputId": "8590ed98-ad39-4c6c-cb77-579bd49da540"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Unknown task text-similarity, available tasks are ['audio-classification', 'automatic-speech-recognition', 'depth-estimation', 'document-question-answering', 'feature-extraction', 'fill-mask', 'image-classification', 'image-feature-extraction', 'image-segmentation', 'image-text-to-text', 'image-to-image', 'image-to-text', 'mask-generation', 'ner', 'object-detection', 'question-answering', 'sentiment-analysis', 'summarization', 'table-question-answering', 'text-classification', 'text-generation', 'text-to-audio', 'text-to-speech', 'text2text-generation', 'token-classification', 'translation', 'video-classification', 'visual-question-answering', 'vqa', 'zero-shot-audio-classification', 'zero-shot-classification', 'zero-shot-image-classification', 'zero-shot-object-detection', 'translation_XX_to_YY']\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-995064974.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;36m10.\u001b[0m\u001b[0mText\u001b[0m \u001b[0mSimilarity\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mMeasuring\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msimilarity\u001b[0m \u001b[0mbetween\u001b[0m \u001b[0mtwo\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m '''\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtext_similarity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text-similarity\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m '''\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/__init__.py\u001b[0m in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, image_processor, processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m    951\u001b[0m             )\n\u001b[1;32m    952\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 953\u001b[0;31m         \u001b[0mnormalized_task\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargeted_task\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    954\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpipeline_class\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m             \u001b[0mpipeline_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargeted_task\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"impl\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/__init__.py\u001b[0m in \u001b[0;36mcheck_task\u001b[0;34m(task)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m     \"\"\"\n\u001b[0;32m--> 526\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mPIPELINE_REGISTRY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mcheck_task\u001b[0;34m(self, task)\u001b[0m\n\u001b[1;32m   1538\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Invalid translation task {task}, use 'translation_XX_to_YY' format\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1540\u001b[0;31m         raise KeyError(\n\u001b[0m\u001b[1;32m   1541\u001b[0m             \u001b[0;34mf\"Unknown task {task}, available tasks are {self.get_supported_tasks() + ['translation_XX_to_YY']}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1542\u001b[0m         )\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Unknown task text-similarity, available tasks are ['audio-classification', 'automatic-speech-recognition', 'depth-estimation', 'document-question-answering', 'feature-extraction', 'fill-mask', 'image-classification', 'image-feature-extraction', 'image-segmentation', 'image-text-to-text', 'image-to-image', 'image-to-text', 'mask-generation', 'ner', 'object-detection', 'question-answering', 'sentiment-analysis', 'summarization', 'table-question-answering', 'text-classification', 'text-generation', 'text-to-audio', 'text-to-speech', 'text2text-generation', 'token-classification', 'translation', 'video-classification', 'visual-question-answering', 'vqa', 'zero-shot-audio-classification', 'zero-shot-classification', 'zero-shot-image-classification', 'zero-shot-object-detection', 'translation_XX_to_YY']\""
     ]
    }
   ],
   "source": [
    "'''\n",
    "10.Text Similarity : Measuring the similarity between two texts.\n",
    "'''\n",
    "text_similarity = pipeline(\"text-similarity\")\n",
    "\n",
    "'''\n",
    "\n",
    "4.Image Generation : Creating new images based on a given prompt.\n",
    "'''\n",
    "image_generator= pipeline(\"image-generation\")\n",
    "\n",
    "'''\n",
    "5.Image Captioning : Generating a textual description of an image.\n",
    "'''\n",
    "image_captioning = pipeline(\"image-captioning\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EImfix0wIvNW"
   },
   "source": [
    "NLP Tasks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iV-WfDZ8I6Wb"
   },
   "source": [
    "1.SENTIMENT ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mBbzyPwHIonY",
    "outputId": "c52e0fed-1bf0-4583-c3a9-afb315e316ef"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9998495578765869}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "classifier =pipeline('sentiment-analysis')\n",
    "res = classifier('I am happy to learn NLP')\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q9_T65tlJMWS",
    "outputId": "395157f9-d9e2-4f48-cb30-8e9907883f1f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9990049004554749}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline(task='sentiment-analysis')('I was confused with Barbie movie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D6UxbQmGKchP",
    "outputId": "b630682b-d435-4198-89e4-f7a48be5eb76"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9784755706787109}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline(task='sentiment-analysis')\\\n",
    " (\"Everyday lots of LLMs papers are published about LLMs Evaluation.\\\n",
    " Lots of them looks very Promising.\\\n",
    " I am not sure if we CAN actually EValuate LLMs.\\\n",
    " There is still lot to do.\\\n",
    " Don't you think? \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245,
     "referenced_widgets": [
      "5265d128fdc9466fbe8961ed7987475e",
      "618928ff90cb40c0957c24219ebb2882",
      "b40c2518101947dc827196ecf134da9c",
      "795d7a3a3a6845ee92cd808aa7bc293e",
      "d7519073dfc8472d8510ba12a72c263b",
      "13fceaa5a7404a238e4fdcfebfe370d9",
      "51b8345f06da4451a2177462d1072de9",
      "85e0d6ecfb064fdda79ac7bcc0387f77",
      "fa1878c882664ecb8d93b1f54bf933f2",
      "f6f12f5dddac4f37ba7776b4fad557e0",
      "4466164bb476458ea4dfc5b27ab13f0d",
      "6b0fd7d8e3eb4fd4ab5aa56b6e580ae9",
      "75bf1b19a9c244aaba87b3ad65fc7b0f",
      "31e8d6704fac4d9889771b74ceab51a2",
      "0d0253d39f17460eb601ec18acb78c68",
      "5827492578e7477898830b8d721e7857",
      "48282ffa19784793932b5ff3ce51a560",
      "82510413f4284538bc5105576bdc776d",
      "c8adf73d873a41c7a0c2489b37c54f33",
      "148cc0d87d0f41fe986113d092bb1b7e",
      "38e96c57b5494cc593dbe6e26a2a803e",
      "97955d79ce2e4a59bf861776733122d8",
      "4a500781d8e34289b6a024b6a1c5bfda",
      "5a26861d43554b589dc555b5402ffe22",
      "b70e404b8ab74d27ac430115154df19a",
      "e5a1b653692a45a6b970121dda343797",
      "e278032d13284c2cbc941f97d8283bb3",
      "aadf52ede715498dbbfb1c6b23338ccf",
      "856960c2047c403aa772ee7f833c404a",
      "2d199d37890244f98b38a9cd119903c3",
      "3700084cc3bf4ab4bac011bc5185d110",
      "4164dee9165c4613bb7a54a42d8c952b",
      "c8db7a401292417aa24e1a7bd17a3cb6",
      "b57cf504e03347ed9d4a1c492d0dbf1e",
      "9f187246da13408fb9501fbb878fab3a",
      "a5e3628b713e46afbf1158e947c07a76",
      "4b224720197e4688a992282dc3c837b9",
      "84519630aabd478b814b50834ec85f29",
      "74edf39be70b46b0aae552da5b1d566b",
      "b7af087841894da4a3b33f1fa3d819b4",
      "bff2bed55f72437097663d8b0e7736a6",
      "d1ebef875f6a48aebe03a9722eaeef09",
      "75ee26f6733b4ea29fc0ccef3a13994e",
      "d7d58281447e4aa2b5a01248a4a17c09",
      "038f10fbbf944ed3bef760dcc27c131e",
      "bd39a3c897b74c86bdc6a59f3b0f853a",
      "8fb1a099ebfd4a5998ff562f89cce822",
      "89f331b3f20b4366998441de02277ffb",
      "94a04a0adfb14fe6949fc03ef958987e",
      "143c4563af954e73a5aad29e5175a6c3",
      "91c1cc67b7f9451f842f0028cb7dd6c5",
      "a5114d7d6bb84df7860bf2e496b25996",
      "488866235fb64a2ab6e319c005fd39c8",
      "d98a1c75cb4f4177b6832e19b2530dcb",
      "a34e8dd799764ae8878f896e3e967aac",
      "89704ce47beb4b1cbab1fcfba7e71781",
      "9ce60f3b0641456ab8fc72d873103e02",
      "eaafb476f2724fd3b2af68998953d1fe",
      "c2b5890efe39437b83f2e17ac5550ba9",
      "31d20e8169954c4d845f6b82dfac17e7",
      "b881fac37e5740b68786bc5b70f10cb1",
      "3e5b82759ed54c15a449c5a19eaf3d16",
      "267ef72642a84189a4a4aba555270617",
      "3b25e38768de4be69fbdb8731d757ebe",
      "0a3d5502a0c0423b98cef7af297a6e41",
      "81797cf643ad444abf9310339602c27f"
     ]
    },
    "id": "8w2vGEJ4L3kO",
    "outputId": "ca0fae10-629f-4683-976b-0e3244973696"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5265d128fdc9466fbe8961ed7987475e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b0fd7d8e3eb4fd4ab5aa56b6e580ae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a500781d8e34289b6a024b6a1c5bfda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b57cf504e03347ed9d4a1c492d0dbf1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "038f10fbbf944ed3bef760dcc27c131e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89704ce47beb4b1cbab1fcfba7e71781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'neutral', 'score': 0.9840484857559204}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LM model for specific task\n",
    "pipeline(task='sentiment-analysis',model='facebook/bart-large-mnli')\\\n",
    " (\"Everyday lots of LLMs papers are published about LLMs Evaluation.\\\n",
    " Lots of them looks very Promising.\\\n",
    " I am not sure if we CAN actually EValuate LLMs.\\\n",
    " There is still lot to do.\\\n",
    " Don't you think? \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4xnLKfcrMqH1"
   },
   "source": [
    "Batch Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AcCGmWM1MD5R",
    "outputId": "0455b7cc-0e68-4840-dda4-dc023fecaa70"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9998495578765869}, {'label': 'NEGATIVE', 'score': 0.9990049004554749}]\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline('sentiment-analysis')\n",
    "res = classifier([\"I am happy to learn NLP\",\n",
    "                  \"I was confused with Barbie movie\"])\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 277,
     "referenced_widgets": [
      "b4af252038ad4cfe92be877794e01a1e",
      "e97c8a571a0d4c36acc146a442430c02",
      "6fe8caf56ab94b808338ca58bb3f482e",
      "bd731272fa544127983924c7051dbb15",
      "82e7921b1f854d38ab2a0b68cc6e7555",
      "c1acf0cea6004f479760aee243d55dda",
      "84a5da49ae47454aa3d4ddd929739f39",
      "388e2ca392ba44d2a1cad540878c8ec5",
      "5321317441e64f518487509314b229d1",
      "a95cac6440914c03a2987f485718ed90",
      "615652cda7bd4f1899276d418ac7fe88",
      "91abeecb9a9d442b8004a4a171ce7754",
      "bc45782adb9b442998c06e141c618b25",
      "79def65ac9e14275a7a97f05a8a3ef92",
      "cc3cd57d24bc4ceb9647dc278367bfb5",
      "5213445bf74d49899f97289023c995fc",
      "225d3e40780744628d537b6bea15ab05",
      "e51c9e8bc16a4ad3ae85008b9f8601f8",
      "b53d7b6d07df46549fba312ea30dda4c",
      "de4958df117e4fed8c3bf051afb9a599",
      "e615115bfdf947fe915886c05f35454b",
      "913fd9adcb174aa693c8aceb12fda92d",
      "be4b5167503044c4848b0f64bd816ba6",
      "6c84dfa19a73429592f6c5475440e148",
      "596dfb3273934f518a0082328c420d3d",
      "947f8b33642a48178b22ac2c1590d5a6",
      "c181ebc4a04c42a0882afe30305af281",
      "6aa7ad06a28041dc837dd0e599b66166",
      "c97c949c24044a3e87593fb0b2fbb8a0",
      "6a659e2a75184fcdbad2811da51b3979",
      "90c5d773ee5348b9824b8bd7aa9af525",
      "505e40e2e4cf48cda17395429a8b327d",
      "13b73efbbcd042569ee8a83e87a75d4e",
      "83257c913160467fa5d937592b2024be",
      "0ea7640105ca4f7bb573ad7bd6003c0b",
      "1fbe062478154c1fb689fdb26ed6d3f1",
      "b8988101f7dc4b61884e69cedeeb8855",
      "413501990d554a48aa2c7c0a0a5a06b2",
      "349140c0ed0a4d76a0f355d0d87000f7",
      "6adefa974b40422e8303fbc5821a7ee3",
      "0617d0e09f3141ea81a8ea720532a288",
      "a044660e34194f94a7fa3397e495f8c0",
      "cd875ca24c59426f9daab75ba51e0bba",
      "2304c615050642758552d62c30f121e2",
      "9567019b3f344dfbab206843377f8bd8",
      "0b3f2a813839431f96995cb25c69effa",
      "66828d069f704f2aaea896651e60473f",
      "c569e64a54b34c83b89ab5ec8f0d4087",
      "db80b5a3395f4b96b9304c0195e39954",
      "66eacf64b50840488c002ac48b0f6bea",
      "bf73a31e20e64e3aa82e75912751a447",
      "7ccab193bd6447d8a42f7325b9d23091",
      "025c827d787c4a71b5868b74f5d1c5aa",
      "0e0dfc7fe6254c8c8414172f140ab999",
      "9c0213d5a46b4478851b4c67ebba22e2",
      "6e7a1e5d3ca140d082ac996bedaa6cdd",
      "c6bdd15914ec49cc86e67a21625fb316",
      "f3a9364b8b234643b3a1a1f2022f46d8",
      "0237cbc320644dbfa18400b4a59e9b34",
      "cf8ea7a5f7384efa954ca521eed43c37",
      "b978b6f0272343ceb20609a206ad0ccf",
      "38c6001d766542de85d266b7cacdede5",
      "05b8ed0ade934f23bfc8ead2ad381881",
      "c563492d56c143dc902cca2695702424",
      "71de29cfaecc4f708ed17d5575e03598",
      "717b46fcf7df4d04b4641f86f6fd8018",
      "d3d8d456d9e0460da7605b80e08c05d3",
      "55fc518c1249490d87e6accb562f362c",
      "41d964ee8db047788aab37712179984f",
      "bf5d589efa614833bcf9feda9d86474c",
      "286c92f2b86949c1a65c58820916b491",
      "dcde38e2f588404689a03b172919f9d8",
      "5c3082eb0a37427a8ea9d1ec4b024896",
      "4a046adf35634a8a8beb826a741efc00",
      "7e5cc7ae3bda4b60a6991cdf9248ad44",
      "2e83808236a047c59f8a759a435c838c",
      "f97ab55a89814fb2ac20eb25e6139268"
     ]
    },
    "id": "zeV_S-dCMzDH",
    "outputId": "28e29f57-bec9-412b-cf0d-ded66a74f4e8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4af252038ad4cfe92be877794e01a1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91abeecb9a9d442b8004a4a171ce7754",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be4b5167503044c4848b0f64bd816ba6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/380 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83257c913160467fa5d937592b2024be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9567019b3f344dfbab206843377f8bd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e7a1e5d3ca140d082ac996bedaa6cdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3d8d456d9e0460da7605b80e08c05d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/280 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'joy', 'score': 0.8995077610015869}, {'label': 'confusion', 'score': 0.9352037906646729}]\n"
     ]
    }
   ],
   "source": [
    "#for getting multiple sentiments\n",
    "classifier = pipeline('sentiment-analysis',model='SamLowe/roberta-base-go_emotions')\n",
    "res = classifier([\"I am happy to learn NLP\",\n",
    "                  \"I was confused with Barbie movie\"])\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lFg3j_SHNRPk"
   },
   "source": [
    "Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 582,
     "referenced_widgets": [
      "f57150ba05b648a6a610a8be6c9d77dc",
      "54286b297a324a7abaeff3fd04ae5dcd",
      "f91614d1a11e4a2897902455b5408862",
      "8793649c88e84bb2acfa8e1f5e8792cd",
      "a81de68225e2415ba8b50669cf5f2458",
      "ad43fa07afeb4dff89cb13070fc75427",
      "e415d38b4b494227a0e3c5aeeb16afeb",
      "8180d283c0e14625a5f106a42e2a7c08",
      "7d07d914c584439fadddcc856155f395",
      "e6639a18da5744d19b758dbba7207162",
      "5c91bd6dcce940da93b80bba17352067",
      "134cf6d0bda64ed3b3f366be781c2bde",
      "f2e064ea1cab46d0bb6e72dfd524346f",
      "a85308b4b95e4624a5ee750a9dea8fab",
      "0545a001a1394ae1bc0d2bb1f136dac5",
      "827c2eb13ab6432585175b9e00a6d8ef",
      "17a714d9d23f4ed79dc1273f1e15616d",
      "8c651139a5bc4b7fa51dc24a1b93a8e3",
      "577c8e98d16a4d9fb66998eaadcde86b",
      "911031eaa09d421e9ab13141bcc752e4",
      "6a0cb35f490144f39f394ba479cb0639",
      "dcc66e9888014c8e9ba7e91648d98a29",
      "ee95c8511b5045b0bcde6a8c783b8264",
      "ffe37b79a26e47dca2cf88ddc8fb6c1c",
      "ba796d1963aa45c6a7547010cda66286",
      "5b38636a8b844f15bdd5f8a8a9409dd4",
      "ce2491399e184cc4af0457c193179160",
      "c68c62a0c6d8444cb68348d0ea47e481",
      "8197ff06bff146d7be247031ebece3bc",
      "2c131079d9f14d098d420b6514132048",
      "f821ed57c9594c4c83e5b1e3134b5273",
      "c85bd8578430424991fed84dfd4de133",
      "3161a9ea73064c6db1552c507714f73d",
      "03235daec5634bdf9d786dcd1b764756",
      "110332d0f5724332912e381a16faed51",
      "e53141234feb425a8adfb07909c6c0a8",
      "529f2873b9ff4de6a8d6259a22b1c9eb",
      "d56cdb258397478ea85c71196e02b330",
      "d8b2263c08004b39905b6a552924564d",
      "d818a9d37b324c3fbf8d105308c794c3",
      "8aebb0d17fc742aa9947fe3467dce01b",
      "5373649726fb4db4b029a8a6269b9990",
      "878d96c5ff604389a9870578c693c3ee",
      "a9d2e3df0cab431298cb6f7893d7b390",
      "2deb54c711a441d984ffda410abed0d9",
      "b532d2363ea24fd783600a52dd040edb",
      "0a071cab45de4f4ca82803fe26bddf63",
      "a1f02292084740ddbbf6f48f3c8570c4",
      "bce332bf02154a5d89fddafd3d9d7bc5",
      "208fcf9ec93f44c181c686d2d7264dbf",
      "a0f1a9ac36d14c1fb9076c3a8da7bf01",
      "8c415587b5db493f8a12a82bdd8329ea",
      "88677467fbd349ff841568cbc6ad98ef",
      "9664730eddd246fcae83245ed0a8ba31",
      "8726c0cea6c0437084cbbe0191c6331c",
      "56ab45ef32c54ba0afbc4e57527c30b1",
      "af2ea073c8424b3cbb49c3b6a8c09afb",
      "07530f43636f4c0385f7a2024ad92dd9",
      "b3fe5f2a04674df381adbab6268db5b0",
      "3311541245ab459b8bffcc76b917e29a",
      "7410f7004b7648c89d2b11da65c1ddc3",
      "dc7ad147bfce4c85bdd1eac16f894977",
      "85f7f76d11914d8a84ab54074ebed9cb",
      "70e6cf986dcf43638a75600dc874aab1",
      "e9a9876c93bf407b849c098d38c594b1",
      "ef7e260d33404d6d9fdf6aa6560d63c4",
      "5a3a41706201421a9043ed656410fbee",
      "7f6a7ea4cfa84078bce5bec535aec5b6",
      "054f58cdd9534b1da362e9fba40463ac",
      "706e8628ca1941e2ab5e669b8960156f",
      "64e4510c725841b9ba4f68ea9d26a531",
      "c7f74b1d9a2f42178b4ae30ae0949c28",
      "f09eb290550d4a329772c315d4057a6f",
      "ec5c2bf0799842b0bc1148f47217892c",
      "52133b0a4d4741399f25cb510757e3dc",
      "1db7a3d95ce84e339e9dc2da82860314",
      "ce281775735a4109b690a57b81791b19"
     ]
    },
    "id": "wJmiulCxNEIY",
    "outputId": "5d4e5156-c321-4511-f02d-60b687bc5f92"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f57150ba05b648a6a610a8be6c9d77dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "134cf6d0bda64ed3b3f366be781c2bde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee95c8511b5045b0bcde6a8c783b8264",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03235daec5634bdf9d786dcd1b764756",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2deb54c711a441d984ffda410abed0d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56ab45ef32c54ba0afbc4e57527c30b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a3a41706201421a9043ed656410fbee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated_text: \n",
      " I am happy to learn NLP has been an absolute success. Im thrilled to work with the people behind NLP and have been very excited to share their vision of the future. The project has been a huge success, and Im very proud of it.\n",
      "\n",
      "\n",
      "Im excited to help people with the creative spirit of this project.\n",
      "Im excited that NLP will allow them to be able to share their vision of the future.\n",
      "I hope that NLP inspires people to do the best they can.\n",
      "Im excited to learn how to create and make a living by making something different.\n",
      "Im excited to learn how to create something different.\n",
      "Im happy to see NLP as a leading medium for learning about the future.\n",
      "NLP is about creating great things.\n",
      "The NLP platform is a great way to start new businesses.\n",
      "Im excited to learn how to create and make a living by making something different.\n",
      "Im happy to learn how to create and make a living by making something different.\n",
      "Im happy to learn how to create and make a living by making something different.\n",
      "The platform is a great way to start new businesses.\n"
     ]
    }
   ],
   "source": [
    "#use a pipeline as a high-level helper\n",
    "generator = pipeline(task='text-generation',model='distilbert/distilgpt2')\n",
    "res = generator('I am happy to learn NLP',truncation=True,num_return_sequences= 2 )\n",
    "print(\"Generated_text: \\n\",res[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2TsS2m7xOaO6"
   },
   "source": [
    "Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RU98NXY9N6n8",
    "outputId": "232836e5-ea3c-4402-e4e9-6f4e680a64d5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 564e9b5 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.9787534475326538, 'start': 25, 'end': 27, 'answer': 'AI'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_model=pipeline(\"question-answering\")\n",
    "question=\"What is a decoder in transformer?\"\n",
    "context = \"I am learning generating AI from scratch.\"\n",
    "qa_model(question=question,context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "TBpFUb75u9MT"
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification,DistilBertTokenizer,DistilBertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 376,
     "referenced_widgets": [
      "289a85234c4d40c3a24aae74dab0b0ed",
      "ebf3b0a228344a88ab13a771128c2ab4",
      "29a4c8f0ba9d4a0aa3c39062cc07fe23",
      "3535d264933e494d954c931b9e8bed4a",
      "28aab2e52ea64a308eaf5b12d49efafb",
      "1a440582ce6e4642af12792ea45b4ec8",
      "33aa0cad20fb4ac29608da391c2eb30f",
      "01f916d8d35b4c5fa7fb5d3bb283dba8",
      "30ddc3e0adc74695be4369d92e357e31",
      "c89d856d9b974e84ab05206c7bd4f91c",
      "8845b81e4a074966b81ffc8efd7ae170",
      "396c8ad1bd3240119423520af2b159ee",
      "ad3f805df294474eab4f72344e93a419",
      "99b76f6906fc4ddfb30b1de1dd104d82",
      "1966ef05289a4d1895933fa621b614c3",
      "8ec1916eb4d644ddabbb3cd14f29b389",
      "2830423d0aab4a228a3cc67f44002320",
      "410a88d0f0834e34ba550611924b35e6",
      "d6246358d38848128901c02e1efdca13",
      "fe925d45535d45f990bae582574e5540",
      "71ec5b394dd144d7a53b329cdb29f299",
      "ebab76750049440ab91f8f111d56c41a",
      "90789abb0c684048a1f904f3d957faf1",
      "d74c7f52018c44438c8d0e848b914b80",
      "f24a74fdd0a94ac487e0d3e8d101836b",
      "0ef1759deec54cc78bf722bcf4262dc8",
      "69c7a5e8944847ca86af57e315380397",
      "714a1488bc1b4457ab2c23443cdad79a",
      "9d84b4821cf74f60b88fd75232a68f94",
      "2854bea674f0423c9ee4dbc351435dfb",
      "ca75bef59e4c4f6392cbc8c1a347dfb7",
      "7487aac1494c466dadd63c91db497ecd",
      "f9ff98d393cf415a96b7e6cfdec61b3a",
      "ec802f2360b547768e1384a6d5013773",
      "2ffb39feeb554d2383b132cf86742d4d",
      "6796b038205d42c08c84a1fcdbc3bcf8",
      "82f5f927c5ff48d288a8cb5f9f604b1a",
      "a115bbe562a24e91bbe7fd06a9dd13da",
      "4ba38d1234fc48c29384741b398b7568",
      "fa30cb91955b46eb9137f0d31511ceed",
      "f86720f7581347a39f0a966baea4e628",
      "3ee45aa4b8804471b319349a99b58a59",
      "9c3770c58ce9477693acedea2925070e",
      "5a976225695d42adaa97dacb651d7d59",
      "7b3023dd0f6c43db9e0d016f686e2fbf",
      "184da9b0bed5462093386ad626f54f62",
      "cf14d990fb134e47889e3d8720d33105",
      "d526d164a01543529fc4a5ddcca374cc",
      "f1d83389eec24e2888ffccfff2e28e5a",
      "01c4262a924d4c1d9ad73f045257c82b",
      "8a39367f548b464e961712c5026df08f",
      "93ccbf743c6948d99bb05e0cc196a698",
      "3497058451434759a1e989dc7e5a19e3",
      "44517861f2b34c5e980a7735f71bdfae",
      "f972242a7b3c4c94b50d50b5f58373c9",
      "e2642ea7cacc47c388f9574a027a3aa3",
      "ccff0a5b81b843e3a1a97c4fc862830f",
      "41b0088a16fb4b6ab9c55f0a20e68d27",
      "f86376add34f4046b59fd9a9b1dfb5c1",
      "d3c60613b6d442ae980062ecef87a7d5",
      "6374b1541e48408e944075ad52dac8f7",
      "e107ad9064114875b32bcab1ac46f18d",
      "109d12b18f10498ab3484b3ec5aaac62",
      "3841caefa7044eaa8c3820c1300c4fcf",
      "fa6c6461fab74b1984cc79bbe4481bb2",
      "886bef13055e4d29adef6fe0e3a6fa6b",
      "9c371c2c0c064b00b7ee0bf54cea3185",
      "3e73de5815b34d47a828338a71d0ea31",
      "28a94a83cb334ca5868371a24d52e85e",
      "25d390231f904491b86f9686e402808f",
      "5f2dd5a57c6b4755b2e3c47fce1366ff",
      "8781cfde07cb426aa191313ea6d8bdb2",
      "127efa51606e4e7795c63cdbe004eb40",
      "fb8240f23e6f4f9da8c426f892fe868b",
      "678b761648fb4d4bac16acd1b252596a",
      "4336b4b1ade2488598014028faa3a03d",
      "16585fccd7d24dd69705d8382f5bbc4a",
      "0f536e843497405d928087678cae5c6a",
      "f7d0823e0b5b4ce09c225c7711fd8e84",
      "d04bd486bfc84ee1926a149dc96d5aca",
      "35b76776dade4489978ca8ebb4ddd6a0",
      "0dcb208c5e63471abd7cd83c7d4bb883",
      "42c5360d3d924a9f8cee5617aef7efd0",
      "58268af60bd6419998449ad3925f5923",
      "4ec725ed68fa4bda83c8e63e606254a6",
      "51b60f98231243da8d8bc6a3315e00c5",
      "3fc68dc91ab74b2f961df75037805071",
      "9f2ac87ca6fd44aabff6e2d95982dc35",
      "9deaaa25570d4b0fa79905915b12cc95",
      "9d01c3ffe903474ea384fb273bc82b10",
      "e2fc7c3b134b4b32869a76f9d6c22963",
      "8445a94ef4324b109a1b4a580d518599",
      "791990fc9f5141f6867bd3071da41a8c",
      "b83fbe391ca6486fb0576c484ba00865",
      "6149118b3151464f94db6c2a48b80eb3",
      "586d21aa4f484fd08255490248a7749d",
      "cb89b72a5d0c45599cdebd588e51ec67",
      "80c0b88e4e8d4c8c9d072300b9e35d95",
      "b7d8fbd5a6864735818e22f812d688b0"
     ]
    },
    "id": "bYsUP5PqO6Q-",
    "outputId": "cedbb8c6-9b5b-46aa-a22f-cdda621c0063"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "289a85234c4d40c3a24aae74dab0b0ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "396c8ad1bd3240119423520af2b159ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90789abb0c684048a1f904f3d957faf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec802f2360b547768e1384a6d5013773",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SST-2 Results: [{'label': 'POSITIVE', 'score': 0.9998495578765869}, {'label': 'NEGATIVE', 'score': 0.9990049004554749}]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b3023dd0f6c43db9e0d016f686e2fbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/39.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2642ea7cacc47c388f9574a027a3aa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/953 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c371c2c0c064b00b7ee0bf54cea3185",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f536e843497405d928087678cae5c6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9deaaa25570d4b0fa79905915b12cc95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/669M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLPTown Results: [{'label': '5 stars', 'score': 0.4859347939491272}, {'label': '3 stars', 'score': 0.2661842703819275}]\n"
     ]
    }
   ],
   "source": [
    "# First model: DistilBERT SST-2\n",
    "model_name1 = 'distilbert-base-uncased-finetuned-sst-2-english'\n",
    "tokenizer1 = AutoTokenizer.from_pretrained(model_name1)\n",
    "model1 = AutoModelForSequenceClassification.from_pretrained(model_name1)\n",
    "\n",
    "classifier1 = pipeline(\"sentiment-analysis\", model=model1, tokenizer=tokenizer1)\n",
    "res1 = classifier1([\n",
    "    \"I am happy to learn NLP\",\n",
    "    \"I was confused with Barbie movie\"\n",
    "])\n",
    "print(\"SST-2 Results:\", res1)\n",
    "\n",
    "# Second model: nlptown multilingual BERT\n",
    "model_name2 = 'nlptown/bert-base-multilingual-uncased-sentiment'\n",
    "tokenizer2 = AutoTokenizer.from_pretrained(model_name2)\n",
    "model2 = AutoModelForSequenceClassification.from_pretrained(model_name2)\n",
    "\n",
    "classifier2 = pipeline(\"sentiment-analysis\", model=model2, tokenizer=tokenizer2)\n",
    "res2 = classifier2([\n",
    "    \"I am happy to learn NLP\",\n",
    "    \"I was confused with Barbie movie\"\n",
    "])\n",
    "print(\"NLPTown Results:\", res2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FFMxlWXDux9j"
   },
   "source": [
    "How tokenizer is working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 236,
     "referenced_widgets": [
      "a664fb82ffc146788e8743cca051e75d",
      "1dadf4c314c44505b597d557f56428d3",
      "d4d4718117e8495ea1cfee663a6162de",
      "3db96a2d8335479cbc73ef5f19200c07",
      "2ad23f8b6b6c4bdb8f91717c58576d11",
      "cdfcd16d341f412ea163ee6c0d0fe47f",
      "94838d41f86046deb879b8e88fcb1268",
      "272e1f3c878345c28d5602a3cc2a27c3",
      "912fe8c3ac674b9dabb9c4c2fcf57c4f",
      "b61979a2a88a40d9aea9bc2aa22e1f17",
      "24cabbd2704b411cb370cb3a759801e6",
      "a68ae77ecdde4d9c992cb0658be10c93",
      "f4fdc06c571545eaa7fcc1e003d76b8c",
      "3450ec35cd724720adad2a5b197dc0d6",
      "49e4265117dd4c3493edac7b16aecd14",
      "098c20f2414641d6a707f4c002569692",
      "b06c250dd98448758a9470c2e63416a0",
      "b1176588123b440ea4e1568d9e769cb7",
      "65539248dc7f4bd6a00c41b3c4d2676b",
      "165cbec20fac4856bfe40f2dda30a6d1",
      "c2aa611b25234039ad5d5efbdb77103d",
      "eb3cc082ce6743c297cc498642b4be79",
      "5181841fa3744612924fca4381eaba39",
      "8f2e3dffed7a44229ab6f1383ccd6749",
      "6b76053b296c44369600c3febfe75295",
      "72b78f4f02e641f78c67a118488aa206",
      "201f2b58fe1a4c92bd9355ce123887dd",
      "8e8c9fccc9c34c288b075ce4ea15f49b",
      "02f7a57c7e304f6284ed4fb53429686c",
      "8a2efa4791ea4f2bae9d3cd8f4c50e7a",
      "0fb2ab9780314d3980dc5c089552ba4a",
      "320bdf9836a3424798343e30f2a922df",
      "22a5cac53f644d2d8aaa771ee6b58858",
      "330a3e1501964789b4f46cb8535791a3",
      "eb90eef3c017452ca3c705e5999d4747",
      "b8032ea87b3c46d08130852bd4e5994d",
      "a3c81b63630d4ea0bc6b77384b14d6e6",
      "d0eed33070df471e872900c38ff1e6f4",
      "5bc076d93e8a4faea4a23d9c9442b223",
      "2747df9a945642c39849633e0d8c9845",
      "2d7f53f47e26474d98a8dd3517c490db",
      "072da3f11f1444cbaa2f9bf85b1b4657",
      "789d93f963a0466db2532b50062aee61",
      "18bdfba03c8943c0ae1e76b891632cba"
     ]
    },
    "id": "37TkhAW5t8XV",
    "outputId": "1281d0d7-8902-4607-babb-5dacef4584f1"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a664fb82ffc146788e8743cca051e75d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a68ae77ecdde4d9c992cb0658be10c93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5181841fa3744612924fca4381eaba39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "330a3e1501964789b4f46cb8535791a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'was', 'so', 'not', 'happy', 'with', 'the', 'barbie', 'movie']\n",
      "Representation of my text :  [1045, 2001, 2061, 2025, 3407, 2007, 1996, 22635, 3185]\n",
      "Encoded Input :  {'input_ids': [101, 1045, 2001, 2061, 2025, 3407, 2007, 1996, 22635, 3185, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "Decoded Output :  i was so not happy with the barbie movie\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "#Load a pre trained tokenizer\n",
    "tokenizer=AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "#Text\n",
    "text='I was so not happy with the Barbie movie'\n",
    "#tokenize the text\n",
    "tokens=tokenizer.tokenize(text)\n",
    "print(tokens)\n",
    "#Convert the tokens into input IDs or vector representation of my text\n",
    "input_ids=tokenizer.convert_tokens_to_ids(tokens)\n",
    "print(\"Representation of my text : \",input_ids)\n",
    "#Encode the text (tokenization + converting the input IDs)\n",
    "encoded_input=tokenizer(text)\n",
    "print('Encoded Input : ',encoded_input)\n",
    "#Decoded the text\n",
    "decoded_output=tokenizer.decode(input_ids)\n",
    "print('Decoded Output : ',decoded_output)\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gWA0kLEexC_9"
   },
   "source": [
    "1)101 : represents start of the sentence.(sos)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ETbqF_3oyecr"
   },
   "source": [
    "2)102 : represents end of the sentence.(eos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x3M6Irfsxcg9"
   },
   "source": [
    "3)attention_mask --> The attention mechanism concept that means whenever we pass the data to the model in which the model will give more weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U0a4vVAgyS3A"
   },
   "source": [
    "4)token_type_ids -->\n",
    "These IDs are used to distinguish between different sequences in tasks that involve multiple sentences, such as question-answering and sentence-pair classification. BERT uses this mechanism to understand which tokens belong to which segment. For single-sequence tasks like sentiment analysis, token_type_ids are all zeros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lTCjWChdzKQy"
   },
   "source": [
    "5)attention_mask-->\n",
    "The attention mask is used to differentiate between actual tokens and padding tokens (if any). It helps the model focus on non-padding tokens and ignore padding tokens, A value of 1 indicates that the token should be attended to, while a value of 0 indicates padding.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7JYFWqguzRKE"
   },
   "source": [
    "6)Why Padding Tokens Are Used\n",
    "Uniform Sequence Length--> Deep learning models typically process input data in batches. To efficiently process these batches, all sequences in a batch mst have the same length. Padding tokens ensure this by extending shorter sequences to match the length of the longest sequence in the batch. Efficient Computation: Fixed-length sequences allow for more efficient use of hardware resources, as the model can process all sequences in paralle without needing to handle variable-length sequences individually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I5_TvGxuzdcR"
   },
   "source": [
    "**Fine Tuning IMDB**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bJ5ugx_7zoIE"
   },
   "source": [
    "step1) install necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "86BmQFmGzlo1",
    "outputId": "e65c0fde-5f08-4736-e76f-24223b1f876c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (4.0.0)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.55.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.34.4)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.8.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade datasets transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b9wRH54Iz6Co"
   },
   "source": [
    "step2) load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Fk7qJNQ0y1Y"
   },
   "source": [
    "Upgrade to latest --> !pip install --upgrade datasets transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "b5n5kxrDzvGi"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"imdb\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mzg9QJWi4hMi",
    "outputId": "70fe4447-1a1b-484f-eb46-f309d9a19380"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 200\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 50\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "Gl-I6-lM0CM0"
   },
   "outputs": [],
   "source": [
    "dataset[\"train\"] = dataset[\"train\"].shuffle(seed=42).select(range(200))\n",
    "dataset[\"test\"] = dataset[\"test\"].shuffle(seed=42).select(range(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xrl7_RIQ0_pT"
   },
   "source": [
    "*Step 3 ) preprosessing the data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "7457d8904c6744fa9b59d37f48bc58d6",
      "be572bc125674be48e7407b7d1059e13",
      "deabd27b8c7e4e59b6c0184656f02fba",
      "ad8d69b834a443e48c9bad8a29b4f7dc",
      "d5100dae6e5b479095dc9d532d2d84d5",
      "eb673006a7c943a3b84d718c2be32b11",
      "8ec8fca3403740a0b5a81ecd3018f633",
      "315cc176a1c14b39a8f5504df3a39e99",
      "f49797a4876743ae904ac917d17af01f",
      "4633bf98d3354e7b860c51fab6ecefc6",
      "4e2418bee6f641868f131b192ec89a02",
      "9867c87b0fc649e2b3044668816bfedf",
      "df85f255f5c24632bd1a3d9a941db2f1",
      "f2ca10b5bf134ff58c020c572a6757dc",
      "4b31c9ac9b374456996b7cecd9692f20",
      "30baf098fe68472aba636ace0289679d",
      "9aefa267d82a457690e340f22104dfed",
      "07e545d2c6874d4184ccbcd8f09d6a72",
      "20d508defd0b41d8bba642dbc1468d8a",
      "38f102747e094feb80dc91a2c4f77698",
      "a0c98cbbc1914cba9a7256dfc21aff29",
      "b5191454962544ee9aaa522317d4b4ed",
      "dd3f97aa691b48438bb292342e108f30",
      "3b1d368ce8244145960bf64467c0bfa2",
      "9c108793e6be454eaf8c86aeddce20af",
      "ece698b81079424db9eb2530d7eb2881",
      "701f64a7a4504769bd198297964d08b8",
      "c853b8f438614a7bbc00a30af48f10e4",
      "f1b3ccb3ae6c4f4bbedd72360a8118aa",
      "b143f491daad4c9fb6e67c86671b3ce1",
      "ca5c10d1377f49d98d149ebac1cb6985",
      "460d92cb940646a78e5f5a1adfee66fc",
      "341a69921de240d59ea96022179f2fa6"
     ]
    },
    "id": "Iv50c7hK0l-M",
    "outputId": "b2347893-ee07-4b61-eddf-b180faa1ea83"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7457d8904c6744fa9b59d37f48bc58d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9867c87b0fc649e2b3044668816bfedf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd3f97aa691b48438bb292342e108f30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
    "\n",
    "# Define tokenization function\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples['text'],\n",
    "        padding='longest',   # pads all sequences to the same length\n",
    "        truncation=True         # cuts off sequences longer than max_length\n",
    "    )\n",
    "\n",
    "# Apply tokenization to dataset\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "SzlUbOAj1dbb",
    "outputId": "3c11c4fb-7782-4d0b-bd4f-a9348740f078"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'There is no relation at all between Fortier and Profiler but the fact that both are police series about violent crimes. Profiler looks crispy, Fortier looks classic. Profiler plots are quite simple. Fortier\\'s plot are far more complicated... Fortier looks more like Prime Suspect, if we have to spot similarities... The main character is weak and weirdo, but have \"clairvoyance\". People like to compare, to judge, to evaluate. How about just enjoying? Funny thing too, people writing Fortier looks American but, on the other hand, arguing they prefer American series (!!!). Maybe it\\'s the language, or the spirit, but I think this series is more English than American. By the way, the actors are really good and funny. The acting is not superficial at all...', 'label': 1, 'input_ids': [101, 1247, 1110, 1185, 6796, 1120, 1155, 1206, 3144, 2852, 1105, 26890, 1197, 1133, 1103, 1864, 1115, 1241, 1132, 2021, 1326, 1164, 5973, 6969, 119, 26890, 1197, 2736, 19501, 1183, 117, 3144, 2852, 2736, 5263, 119, 26890, 1197, 15836, 1132, 2385, 3014, 119, 3144, 2852, 112, 188, 4928, 1132, 1677, 1167, 8277, 119, 119, 119, 3144, 2852, 2736, 1167, 1176, 3460, 15463, 20629, 117, 1191, 1195, 1138, 1106, 3205, 12672, 119, 119, 119, 1109, 1514, 1959, 1110, 4780, 1105, 6994, 1186, 117, 1133, 1138, 107, 172, 20293, 12716, 3923, 107, 119, 2563, 1176, 1106, 14133, 117, 1106, 3942, 117, 1106, 17459, 119, 1731, 1164, 1198, 8965, 136, 16819, 1645, 1315, 117, 1234, 2269, 3144, 2852, 2736, 1237, 1133, 117, 1113, 1103, 1168, 1289, 117, 8995, 1152, 9353, 1237, 1326, 113, 106, 106, 106, 114, 119, 2389, 1122, 112, 188, 1103, 1846, 117, 1137, 1103, 4840, 117, 1133, 146, 1341, 1142, 1326, 1110, 1167, 1483, 1190, 1237, 119, 1650, 1103, 1236, 117, 1103, 5681, 1132, 1541, 1363, 1105, 6276, 119, 1109, 3176, 1110, 1136, 26558, 1120, 1155, 119, 119, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "{'text': \"<br /><br />When I unsuspectedly rented A Thousand Acres, I thought I was in for an entertaining King Lear story and of course Michelle Pfeiffer was in it, so what could go wrong?<br /><br />Very quickly, however, I realized that this story was about A Thousand Other Things besides just Acres. I started crying and couldn't stop until long after the movie ended. Thank you Jane, Laura and Jocelyn, for bringing us such a wonderfully subtle and compassionate movie! Thank you cast, for being involved and portraying the characters with such depth and gentleness!<br /><br />I recognized the Angry sister; the Runaway sister and the sister in Denial. I recognized the Abusive Husband and why he was there and then the Father, oh oh the Father... all superbly played. I also recognized myself and this movie was an eye-opener, a relief, a chance to face my OWN truth and finally doing something about it. I truly hope A Thousand Acres has had the same effect on some others out there.<br /><br />Since I didn't understand why the cover said the film was about sisters fighting over land -they weren't fighting each other at all- I watched it a second time. Then I was able to see that if one hadn't lived a similar story, one would easily miss the overwhelming undercurrent of dread and fear and the deep bond between the sisters that runs through it all. That is exactly the reason why people in general often overlook the truth about their neighbors for instance.<br /><br />But yet another reason why this movie is so perfect!<br /><br />I don't give a rat's ass (pardon my French) about to what extend the King Lear story is followed. All I know is that I can honestly say: this movie has changed my life.<br /><br />Keep up the good work guys, you CAN and DO make a difference.<br /><br />\", 'label': 1, 'input_ids': [101, 133, 9304, 120, 135, 133, 9304, 120, 135, 1332, 146, 8362, 14410, 26426, 17797, 12765, 138, 19223, 138, 13782, 1116, 117, 146, 1354, 146, 1108, 1107, 1111, 1126, 15021, 1624, 12958, 1197, 1642, 1105, 1104, 1736, 9075, 153, 8124, 11093, 1200, 1108, 1107, 1122, 117, 1177, 1184, 1180, 1301, 2488, 136, 133, 9304, 120, 135, 133, 9304, 120, 135, 6424, 1976, 117, 1649, 117, 146, 2788, 1115, 1142, 1642, 1108, 1164, 138, 19223, 2189, 7149, 8655, 1198, 138, 13782, 1116, 119, 146, 1408, 6675, 1105, 1577, 112, 189, 1831, 1235, 1263, 1170, 1103, 2523, 2207, 119, 4514, 1128, 4074, 117, 6273, 1105, 26653, 117, 1111, 4362, 1366, 1216, 170, 7310, 1193, 11515, 1105, 18027, 2193, 2523, 106, 4514, 1128, 2641, 117, 1111, 1217, 2017, 1105, 18712, 1103, 2650, 1114, 1216, 5415, 1105, 6892, 1757, 106, 133, 9304, 120, 135, 133, 9304, 120, 135, 146, 3037, 1103, 24991, 2104, 132, 1103, 6728, 7138, 2104, 1105, 1103, 2104, 1107, 14760, 2916, 119, 146, 3037, 1103, 8158, 8788, 20164, 22309, 1105, 1725, 1119, 1108, 1175, 1105, 1173, 1103, 4505, 117, 9294, 9294, 1103, 4505, 119, 119, 119, 1155, 25876, 1193, 1307, 119, 146, 1145, 3037, 1991, 1105, 1142, 2523, 1108, 1126, 2552, 118, 17622, 117, 170, 3893, 117, 170, 2640, 1106, 1339, 1139, 152, 2924, 2249, 3062, 1105, 1921, 1833, 1380, 1164, 1122, 119, 146, 5098, 2810, 138, 19223, 138, 13782, 1116, 1144, 1125, 1103, 1269, 2629, 1113, 1199, 1639, 1149, 1175, 119, 133, 9304, 120, 135, 133, 9304, 120, 135, 1967, 146, 1238, 112, 189, 2437, 1725, 1103, 2267, 1163, 1103, 1273, 1108, 1164, 5919, 2935, 1166, 1657, 118, 1152, 3920, 112, 189, 2935, 1296, 1168, 1120, 1155, 118, 146, 2542, 1122, 170, 1248, 1159, 119, 1599, 146, 1108, 1682, 1106, 1267, 1115, 1191, 1141, 2018, 112, 189, 2077, 170, 1861, 1642, 117, 1141, 1156, 3253, 5529, 1103, 10827, 1223, 21754, 1104, 18410, 1105, 2945, 1105, 1103, 1996, 7069, 1206, 1103, 5919, 1115, 2326, 1194, 1122, 1155, 119, 1337, 1110, 2839, 1103, 2255, 1725, 1234, 1107, 1704, 1510, 1166, 21163, 1103, 3062, 1164, 1147, 11209, 1111, 5374, 119, 133, 9304, 120, 135, 133, 9304, 120, 135, 1252, 1870, 1330, 2255, 1725, 1142, 2523, 1110, 1177, 3264, 106, 133, 9304, 120, 135, 133, 9304, 120, 135, 146, 1274, 112, 189, 1660, 170, 11631, 112, 188, 3919, 113, 19015, 1139, 1497, 114, 1164, 1106, 1184, 7532, 1103, 1624, 12958, 1197, 1642, 1110, 1723, 119, 1398, 146, 1221, 1110, 1115, 146, 1169, 12051, 1474, 131, 1142, 2523, 1144, 2014, 1139, 1297, 119, 133, 9304, 120, 135, 133, 9304, 120, 135, 7947, 1146, 1103, 1363, 1250, 3713, 117, 1128, 8784, 2249, 1105, 141, 2346, 1294, 170, 3719, 119, 133, 9304, 120, 135, 133, 9304, 120, 135, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_datasets[\"train\"][0])\n",
    "print(tokenized_datasets[\"test\"][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kg_Zo-cQ5Tfg",
    "outputId": "958a8a08-2cc4-47e1-c503-7db07de1fae1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'There is no relation at all between Fortier and Profiler but the fact that both are police series about violent crimes. Profiler looks crispy, Fortier looks classic. Profiler plots are quite simple. Fortier\\'s plot are far more complicated... Fortier looks more like Prime Suspect, if we have to spot similarities... The main character is weak and weirdo, but have \"clairvoyance\". People like to compare, to judge, to evaluate. How about just enjoying? Funny thing too, people writing Fortier looks American but, on the other hand, arguing they prefer American series (!!!). Maybe it\\'s the language, or the spirit, but I think this series is more English than American. By the way, the actors are really good and funny. The acting is not superficial at all...',\n",
       " 'label': 1,\n",
       " 'input_ids': [101,\n",
       "  1247,\n",
       "  1110,\n",
       "  1185,\n",
       "  6796,\n",
       "  1120,\n",
       "  1155,\n",
       "  1206,\n",
       "  3144,\n",
       "  2852,\n",
       "  1105,\n",
       "  26890,\n",
       "  1197,\n",
       "  1133,\n",
       "  1103,\n",
       "  1864,\n",
       "  1115,\n",
       "  1241,\n",
       "  1132,\n",
       "  2021,\n",
       "  1326,\n",
       "  1164,\n",
       "  5973,\n",
       "  6969,\n",
       "  119,\n",
       "  26890,\n",
       "  1197,\n",
       "  2736,\n",
       "  19501,\n",
       "  1183,\n",
       "  117,\n",
       "  3144,\n",
       "  2852,\n",
       "  2736,\n",
       "  5263,\n",
       "  119,\n",
       "  26890,\n",
       "  1197,\n",
       "  15836,\n",
       "  1132,\n",
       "  2385,\n",
       "  3014,\n",
       "  119,\n",
       "  3144,\n",
       "  2852,\n",
       "  112,\n",
       "  188,\n",
       "  4928,\n",
       "  1132,\n",
       "  1677,\n",
       "  1167,\n",
       "  8277,\n",
       "  119,\n",
       "  119,\n",
       "  119,\n",
       "  3144,\n",
       "  2852,\n",
       "  2736,\n",
       "  1167,\n",
       "  1176,\n",
       "  3460,\n",
       "  15463,\n",
       "  20629,\n",
       "  117,\n",
       "  1191,\n",
       "  1195,\n",
       "  1138,\n",
       "  1106,\n",
       "  3205,\n",
       "  12672,\n",
       "  119,\n",
       "  119,\n",
       "  119,\n",
       "  1109,\n",
       "  1514,\n",
       "  1959,\n",
       "  1110,\n",
       "  4780,\n",
       "  1105,\n",
       "  6994,\n",
       "  1186,\n",
       "  117,\n",
       "  1133,\n",
       "  1138,\n",
       "  107,\n",
       "  172,\n",
       "  20293,\n",
       "  12716,\n",
       "  3923,\n",
       "  107,\n",
       "  119,\n",
       "  2563,\n",
       "  1176,\n",
       "  1106,\n",
       "  14133,\n",
       "  117,\n",
       "  1106,\n",
       "  3942,\n",
       "  117,\n",
       "  1106,\n",
       "  17459,\n",
       "  119,\n",
       "  1731,\n",
       "  1164,\n",
       "  1198,\n",
       "  8965,\n",
       "  136,\n",
       "  16819,\n",
       "  1645,\n",
       "  1315,\n",
       "  117,\n",
       "  1234,\n",
       "  2269,\n",
       "  3144,\n",
       "  2852,\n",
       "  2736,\n",
       "  1237,\n",
       "  1133,\n",
       "  117,\n",
       "  1113,\n",
       "  1103,\n",
       "  1168,\n",
       "  1289,\n",
       "  117,\n",
       "  8995,\n",
       "  1152,\n",
       "  9353,\n",
       "  1237,\n",
       "  1326,\n",
       "  113,\n",
       "  106,\n",
       "  106,\n",
       "  106,\n",
       "  114,\n",
       "  119,\n",
       "  2389,\n",
       "  1122,\n",
       "  112,\n",
       "  188,\n",
       "  1103,\n",
       "  1846,\n",
       "  117,\n",
       "  1137,\n",
       "  1103,\n",
       "  4840,\n",
       "  117,\n",
       "  1133,\n",
       "  146,\n",
       "  1341,\n",
       "  1142,\n",
       "  1326,\n",
       "  1110,\n",
       "  1167,\n",
       "  1483,\n",
       "  1190,\n",
       "  1237,\n",
       "  119,\n",
       "  1650,\n",
       "  1103,\n",
       "  1236,\n",
       "  117,\n",
       "  1103,\n",
       "  5681,\n",
       "  1132,\n",
       "  1541,\n",
       "  1363,\n",
       "  1105,\n",
       "  6276,\n",
       "  119,\n",
       "  1109,\n",
       "  3176,\n",
       "  1110,\n",
       "  1136,\n",
       "  26558,\n",
       "  1120,\n",
       "  1155,\n",
       "  119,\n",
       "  119,\n",
       "  119,\n",
       "  102,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'token_type_ids': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0]}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RU1UTLkh2-QL"
   },
   "source": [
    "step 4 )setup training arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "5AHUu75c2x8E",
    "outputId": "7ceea791-7082-4904-a4e9-88a3e2612c26"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainingArguments(\n",
       "_n_gpu=1,\n",
       "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
       "adafactor=False,\n",
       "adam_beta1=0.9,\n",
       "adam_beta2=0.999,\n",
       "adam_epsilon=1e-08,\n",
       "auto_find_batch_size=False,\n",
       "average_tokens_across_devices=False,\n",
       "batch_eval_metrics=False,\n",
       "bf16=False,\n",
       "bf16_full_eval=False,\n",
       "data_seed=None,\n",
       "dataloader_drop_last=False,\n",
       "dataloader_num_workers=0,\n",
       "dataloader_persistent_workers=False,\n",
       "dataloader_pin_memory=True,\n",
       "dataloader_prefetch_factor=None,\n",
       "ddp_backend=None,\n",
       "ddp_broadcast_buffers=None,\n",
       "ddp_bucket_cap_mb=None,\n",
       "ddp_find_unused_parameters=None,\n",
       "ddp_timeout=1800,\n",
       "debug=[],\n",
       "deepspeed=None,\n",
       "disable_tqdm=False,\n",
       "do_eval=True,\n",
       "do_predict=False,\n",
       "do_train=False,\n",
       "eval_accumulation_steps=None,\n",
       "eval_delay=0,\n",
       "eval_do_concat_batches=True,\n",
       "eval_on_start=False,\n",
       "eval_steps=None,\n",
       "eval_strategy=IntervalStrategy.EPOCH,\n",
       "eval_use_gather_object=False,\n",
       "fp16=False,\n",
       "fp16_backend=auto,\n",
       "fp16_full_eval=False,\n",
       "fp16_opt_level=O1,\n",
       "fsdp=[],\n",
       "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
       "fsdp_min_num_params=0,\n",
       "fsdp_transformer_layer_cls_to_wrap=None,\n",
       "full_determinism=False,\n",
       "gradient_accumulation_steps=1,\n",
       "gradient_checkpointing=False,\n",
       "gradient_checkpointing_kwargs=None,\n",
       "greater_is_better=None,\n",
       "group_by_length=False,\n",
       "half_precision_backend=auto,\n",
       "hub_always_push=False,\n",
       "hub_model_id=None,\n",
       "hub_private_repo=None,\n",
       "hub_revision=None,\n",
       "hub_strategy=HubStrategy.EVERY_SAVE,\n",
       "hub_token=<HUB_TOKEN>,\n",
       "ignore_data_skip=False,\n",
       "include_for_metrics=[],\n",
       "include_inputs_for_metrics=False,\n",
       "include_num_input_tokens_seen=False,\n",
       "include_tokens_per_second=False,\n",
       "jit_mode_eval=False,\n",
       "label_names=None,\n",
       "label_smoothing_factor=0.0,\n",
       "learning_rate=2e-05,\n",
       "length_column_name=length,\n",
       "liger_kernel_config=None,\n",
       "load_best_model_at_end=False,\n",
       "local_rank=0,\n",
       "log_level=passive,\n",
       "log_level_replica=warning,\n",
       "log_on_each_node=True,\n",
       "logging_dir=./results/runs/Aug19_05-40-10_33d6becb96ce,\n",
       "logging_first_step=False,\n",
       "logging_nan_inf_filter=True,\n",
       "logging_steps=500,\n",
       "logging_strategy=IntervalStrategy.STEPS,\n",
       "lr_scheduler_kwargs={},\n",
       "lr_scheduler_type=SchedulerType.LINEAR,\n",
       "max_grad_norm=1.0,\n",
       "max_steps=-1,\n",
       "metric_for_best_model=None,\n",
       "mp_parameters=,\n",
       "neftune_noise_alpha=None,\n",
       "no_cuda=False,\n",
       "num_train_epochs=3,\n",
       "optim=OptimizerNames.ADAMW_TORCH,\n",
       "optim_args=None,\n",
       "optim_target_modules=None,\n",
       "output_dir=./results,\n",
       "overwrite_output_dir=False,\n",
       "past_index=-1,\n",
       "per_device_eval_batch_size=4,\n",
       "per_device_train_batch_size=4,\n",
       "prediction_loss_only=False,\n",
       "push_to_hub=False,\n",
       "push_to_hub_model_id=None,\n",
       "push_to_hub_organization=None,\n",
       "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
       "ray_scope=last,\n",
       "remove_unused_columns=True,\n",
       "report_to=['tensorboard', 'wandb'],\n",
       "restore_callback_states_from_checkpoint=False,\n",
       "resume_from_checkpoint=None,\n",
       "run_name=None,\n",
       "save_on_each_node=False,\n",
       "save_only_model=False,\n",
       "save_safetensors=True,\n",
       "save_steps=500,\n",
       "save_strategy=SaveStrategy.STEPS,\n",
       "save_total_limit=None,\n",
       "seed=42,\n",
       "skip_memory_metrics=True,\n",
       "tf32=None,\n",
       "torch_compile=False,\n",
       "torch_compile_backend=None,\n",
       "torch_compile_mode=None,\n",
       "torch_empty_cache_steps=None,\n",
       "torchdynamo=None,\n",
       "tpu_metrics_debug=False,\n",
       "tpu_num_cores=None,\n",
       "use_cpu=False,\n",
       "use_ipex=False,\n",
       "use_legacy_prediction_loop=False,\n",
       "use_liger_kernel=False,\n",
       "use_mps_device=False,\n",
       "warmup_ratio=0.0,\n",
       "warmup_steps=0,\n",
       "weight_decay=0.01,\n",
       ")"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args=TrainingArguments(output_dir='./results', #Output directory\n",
    "                                eval_strategy=\"epoch\",  #Evaluate every epoch\n",
    "                                learning_rate=2e-5,     #Learning rate\n",
    "                                per_device_train_batch_size=4, #Batch size for training\n",
    "                                per_device_eval_batch_size=4, #Batch size for evaluation\n",
    "                                num_train_epochs=3, #number of training epochs\n",
    "                                weight_decay=0.01 # Strength of weight decay\n",
    ")\n",
    "training_args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OPTw64K84O7t"
   },
   "source": [
    "Step 5 ) Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "Y6PsgV-qzMPU"
   },
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137,
     "referenced_widgets": [
      "a5991bdaaf4842e596483519a253731a",
      "888eb408509147978ca95077f5e33a43",
      "4ec3bd23d5b8406792220814358c5296",
      "91e1b7bae0e64398bca83505f2625938",
      "16c12aa542ab4654a93bad48e4549f0b",
      "873b66a4d4454fb98cbacd2d0d23a3a7",
      "2c594a68e5974e319d563df503e528b1",
      "7bdaa3b905ca4506b0f27431942b36a5",
      "45cddd03e7c74e03889420b63ae19852",
      "2e5dbeaf78d6456da28c151269dee855",
      "13054f3332e4473ba35150fa21359df2",
      "2a2827f9189845b085aa6b133b4e8cd2",
      "606da01a6ac143e8adf5e7340aab865e",
      "62b566d2784c4abdbe01cff63baafd13",
      "4b29efbb44d44b6caea2d06201a3388c",
      "49d18ff18f8d4ecf83960b215225eb48",
      "b02a0610b76a4f0e9fb8308ed218e2c3",
      "01878a64ecd543569108fedd0f553760",
      "5a88208106f34273ba49f0d7d8e56bff",
      "d0eae2f8268e42fabe4c9580f72a1a9f",
      "29de9bc3b71d48f4911524f970739096",
      "390e8f8cef49448f9dd961314b43d326"
     ]
    },
    "id": "e6xFfri53oEo",
    "outputId": "7afd8d44-a5b8-4e77-f59a-501c120f26d8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5991bdaaf4842e596483519a253731a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a2827f9189845b085aa6b133b4e8cd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, Trainer\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = AutoModelForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)\n",
    "#Initialize the trainer\n",
    "trainer=Trainer(model=model,args=training_args,train_dataset=tokenized_datasets['train'],eval_dataset=tokenized_datasets['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5cr1zKK65KlT"
   },
   "source": [
    "Step 6 ) Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 205
    },
    "id": "ZtnQsx5e5Chr",
    "outputId": "5e5dcbd6-6fb6-45ac-cfec-92751dc09c77"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [150/150 00:48, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.687836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.692517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.690085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=150, training_loss=0.6942327372233073, metrics={'train_runtime': 48.8651, 'train_samples_per_second': 12.279, 'train_steps_per_second': 3.07, 'total_flos': 79480439193600.0, 'train_loss': 0.6942327372233073, 'epoch': 3.0})"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yTdSf67IRyiX"
   },
   "source": [
    "Step 7 ) Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "id": "HGm5T1hp5TpC",
    "outputId": "56f8e25a-f76d-49a6-a747-4896bffa6068"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6900845170021057, 'eval_runtime': 0.822, 'eval_samples_per_second': 60.828, 'eval_steps_per_second': 15.815, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the model\n",
    "results = trainer.evaluate()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B5S1VTXJSAFr"
   },
   "source": [
    "Step 8 ) Save the fine tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ye-FMpqqPDr4",
    "outputId": "21a8e9ba-cd83-41ef-a72b-48805e5e924f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./fine_tuned-model/tokenizer_config.json',\n",
       " './fine_tuned-model/special_tokens_map.json',\n",
       " './fine_tuned-model/vocab.txt',\n",
       " './fine_tuned-model/added_tokens.json',\n",
       " './fine_tuned-model/tokenizer.json')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save the model\n",
    "model.save_pretrained('./fine_tuned-model')\n",
    "tokenizer.save_pretrained('./fine_tuned-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eXnov6-c16Et"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
